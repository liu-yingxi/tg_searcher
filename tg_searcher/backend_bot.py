# -*- coding: utf-8 -*-
import html
import asyncio # ç”¨äºå¼‚æ­¥æ“ä½œï¼Œå¦‚ sleep
from datetime import datetime
from typing import Optional, List, Set, Dict, Any, Union, Tuple # æ·»åŠ  Any, Tuple

import telethon.errors.rpcerrorlist
from telethon import events
from telethon.tl.patched import Message as TgMessage
from telethon.tl.types import User
from whoosh.query import Term # ç”¨äºæ„å»ºæŸ¥è¯¢
# ç§»é™¤ searching å¯¼å…¥ï¼Œå› ä¸ºå®ƒæ²¡æœ‰ SearchError
from whoosh import writing, index as whoosh_index
from whoosh.writing import IndexWriter, LockError # å†™å…¥å’Œé”é”™è¯¯

# é¡¹ç›®å†…å¯¼å…¥ - ä½¿ç”¨åŒ…å«æ–‡ä»¶ç´¢å¼•çš„ Indexer
from .indexer import Indexer, IndexMsg, SearchResult
from .common import CommonBotConfig, escape_content, get_share_id, get_logger, format_entity_name, brief_content, \
    EntityNotFoundError
from .session import ClientSession


# æ—¥å¿—è®°å½•å™¨
logger = get_logger('backend_bot') # logger åœ¨æ¨¡å—çº§åˆ«å®šä¹‰ï¼Œæ‰€æœ‰å®ä¾‹å…±äº«


class BackendBotConfig:
    """å­˜å‚¨ Backend Bot é…ç½®çš„ç±» - åŸºäºä½ æä¾›çš„æ–‡ä»¶ç»“æ„"""
    def __init__(self, **kw: Any):
        self.monitor_all: bool = kw.get('monitor_all', False) # æ˜¯å¦ç›‘æ§æ‰€æœ‰åŠ å…¥çš„å¯¹è¯
        # åŸå§‹æ’é™¤åˆ—è¡¨ï¼Œå¯èƒ½åŒ…å«ç”¨æˆ·åæˆ– ID
        self._raw_exclude_chats: List[Union[int, str]] = kw.get('exclude_chats', [])
        # è§£æåçš„æ’é™¤åˆ—è¡¨ (ä»…å« share_id)
        self.excluded_chats: Set[int] = set()
        # åˆå§‹åŒ–æ—¶å°è¯•è§£ææ•´æ•° ID
        for chat_id_or_name in self._raw_exclude_chats:
            try:
                # ç¡®ä¿è¾“å…¥æ˜¯æ•°å­—æˆ–å¯è½¬æ¢ä¸ºæ•°å­—çš„å­—ç¬¦ä¸²
                numeric_id = int(chat_id_or_name)
                self.excluded_chats.add(get_share_id(numeric_id))
            except (ValueError, TypeError):
                 # éæ•°å­—ç•™ç»™ start() è§£æ (å¦‚æœæ˜¯ç”¨æˆ·å)
                 pass


class BackendBot:
    """å¤„ç†ç´¢å¼•ã€ä¸‹è½½ã€åå°ç›‘æ§çš„æ ¸å¿ƒ Bot ç±» - åŒ…å«æ–‡ä»¶ç´¢å¼•é€»è¾‘å’Œä¿®å¤"""
    def __init__(self, common_cfg: CommonBotConfig, cfg: BackendBotConfig,
                 session: ClientSession, clean_db: bool, backend_id: str):
        """åˆå§‹åŒ– Backend Bot"""
        self.id: str = backend_id # åç«¯å®ä¾‹ ID
        self.session = session # åº•å±‚çš„ Telethon å®¢æˆ·ç«¯ä¼šè¯

        # ä½¿ç”¨ç‰¹å®šäºæ­¤åç«¯å®ä¾‹çš„ logger
        self._logger = get_logger(f'bot-backend:{backend_id}')
        self._cfg = cfg # åç«¯ç‰¹å®šé…ç½®
        # åˆå§‹åŒ– Indexer
        if clean_db: self._logger.info(f'Index will be cleaned for backend {backend_id}')
        try:
            # ä½¿ç”¨åŒ…å«æ–‡ä»¶å­—æ®µçš„ Indexer
            self._indexer: Indexer = Indexer(common_cfg.index_dir / backend_id, clean_db)
        except ValueError as e: self._logger.critical(f"Indexer initialization failed: {e}"); raise
        except Exception as e: self._logger.critical(f"Unexpected error initializing indexer: {e}", exc_info=True); raise

        # åŠ è½½å·²ç›‘æ§çš„å¯¹è¯åˆ—è¡¨
        try:
            # ä»ç´¢å¼•ä¸­åŠ è½½å·²ç›‘æ§çš„å¯¹è¯ ID
            self.monitored_chats: Set[int] = self._indexer.list_indexed_chats()
            self._logger.info(f"Loaded {len(self.monitored_chats)} monitored chats from index")
        except Exception as e:
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåˆå§‹åŒ–ä¸ºç©ºé›†åˆå¹¶è®°å½•é”™è¯¯
            self._logger.error(f"Failed to list indexed chats on startup: {e}", exc_info=True)
            self.monitored_chats = set()

        # å­˜å‚¨æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨ (åŒ…æ‹¬å¯åŠ¨æ—¶è§£æçš„)
        # è¿™é‡Œå°†é…ç½®ä¸­çš„æ•´æ•°IDè§£æç»“æœä¸å¯åŠ¨æ—¶å¯èƒ½è§£æçš„ç”¨æˆ·åç»“æœåˆå¹¶
        # æ³¨æ„ï¼š_raw_exclude_chats ä¸»è¦ç”¨äºå¯åŠ¨æ—¶è§£æç”¨æˆ·å
        self.excluded_chats: Set[int] = cfg.excluded_chats
        self._raw_exclude_chats: List[Union[int, str]] = cfg._raw_exclude_chats # ä¿ç•™åŸå§‹é…ç½®ï¼Œç”¨äºstartè§£æ
        # ç¼“å­˜æ¯ä¸ªç›‘æ§å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯ {chat_id: IndexMsg}
        self.newest_msg: Dict[int, IndexMsg] = dict()
        # è·Ÿè¸ªåå°ä»»åŠ¡ï¼Œä¾‹å¦‚ä¸‹è½½å†å²è®°å½•
        self._background_tasks: Set[asyncio.Task] = set()


    def _load_newest_messages_on_startup(self):
         """å¯åŠ¨æ—¶ä¸ºæ¯ä¸ªç›‘æ§çš„å¯¹è¯åŠ è½½æœ€æ–°æ¶ˆæ¯åˆ°ç¼“å­˜"""
         if not self.monitored_chats:
             self._logger.info("No monitored chats found in index, skipping loading newest messages.")
             return
         self._logger.info("Loading newest message for each monitored chat...")
         count = 0
         # è¿­ä»£ monitored_chats çš„å‰¯æœ¬ï¼Œä»¥é˜²åœ¨åŠ è½½æœŸé—´åˆ—è¡¨è¢«ä¿®æ”¹
         for chat_id in list(self.monitored_chats):
              # è·³è¿‡å·²åœ¨æ’é™¤åˆ—è¡¨ä¸­çš„å¯¹è¯
              if chat_id in self.excluded_chats:
                  self._logger.debug(f"Skipping loading newest message for excluded chat {chat_id}.")
                  continue
              try:
                   # æœç´¢è¯¥å¯¹è¯çš„æœ€æ–°ä¸€æ¡æ¶ˆæ¯
                   # ä½¿ç”¨ q_str='*' åŒ¹é…æ‰€æœ‰æ–‡æ¡£ï¼ŒæŒ‰æ—¶é—´å€’åºï¼Œåªå–ç¬¬ä¸€æ¡
                   result = self._indexer.search(q_str='*', in_chats=[chat_id], page_len=1, page_num=1, file_filter="all")
                   if result.hits:
                       self.newest_msg[chat_id] = result.hits[0].msg
                       count += 1
                       self._logger.debug(f"Loaded newest message for chat {chat_id}: {result.hits[0].msg.url}")
                   else:
                       self._logger.debug(f"No messages found in index for chat {chat_id} to load as newest.")
              except Exception as e:
                  # è®°å½•åŠ è½½ç‰¹å®šå¯¹è¯æœ€æ–°æ¶ˆæ¯æ—¶çš„é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹
                  self._logger.warning(f"Failed to load newest message for chat {chat_id}: {e}")
         self._logger.info(f"Finished loading newest messages for {count} monitored (and not excluded) chats.")


    async def start(self):
        """å¯åŠ¨ Backend Bot"""
        self._logger.info(f'Starting backend bot {self.id}...')

        # è§£æé…ç½®ä¸­å¯èƒ½æ˜¯ç”¨æˆ·åçš„ exclude_chats
        resolved_excludes_in_cfg = set()
        for chat_id_or_name in self._raw_exclude_chats:
            # åªå¤„ç†éæ•°å­—å­—ç¬¦ä¸²ï¼Œå°è¯•å°†å…¶è§£æä¸º share_id
            if isinstance(chat_id_or_name, str) and not chat_id_or_name.lstrip('-').isdigit():
                 try:
                      share_id = await self.str_to_chat_id(chat_id_or_name) # å°è¯•è§£æ
                      resolved_excludes_in_cfg.add(share_id)
                      self._logger.info(f"Resolved exclude chat '{chat_id_or_name}' to ID {share_id}")
                 except EntityNotFoundError:
                     # å¦‚æœæ‰¾ä¸åˆ°å®ä½“ï¼Œè®°å½•è­¦å‘Šå¹¶å¿½ç•¥
                     self._logger.warning(f"Exclude chat '{chat_id_or_name}' not found, ignoring.")
                 except Exception as e:
                     # è®°å½•è§£æè¿‡ç¨‹ä¸­çš„å…¶ä»–é”™è¯¯
                     self._logger.error(f"Error resolving exclude chat '{chat_id_or_name}': {e}")

        # æ›´æ–°æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨ï¼Œåˆå¹¶æ¥è‡ªé…ç½®çš„è§£æç»“æœ
        self.excluded_chats.update(resolved_excludes_in_cfg)
        self._logger.info(f"Final excluded chats for backend {self.id}: {self.excluded_chats or 'None'}")

        # åŠ è½½æœ€æ–°æ¶ˆæ¯ç¼“å­˜ (åœ¨å¤„ç†æ’é™¤åˆ—è¡¨å’ŒéªŒè¯ç›‘æ§åˆ—è¡¨ä¹‹å‰)
        self._load_newest_messages_on_startup()

        # å¯åŠ¨æ—¶æ£€æŸ¥ç›‘æ§çš„èŠå¤©æ˜¯å¦ä»ç„¶å¯è®¿é—®ï¼Œå¹¶ç§»é™¤æ— æ•ˆçš„æˆ–è¢«æ’é™¤çš„
        chats_to_remove = set()
        # è¿­ä»£ monitored_chats çš„å‰¯æœ¬è¿›è¡Œæ£€æŸ¥
        for chat_id in list(self.monitored_chats):
            try:
                # å¦‚æœå¯¹è¯åœ¨æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨ä¸­ï¼Œå°†å…¶æ ‡è®°ä¸ºç§»é™¤
                if chat_id in self.excluded_chats:
                     self._logger.info(f"Chat {chat_id} is excluded, removing from monitoring.")
                     chats_to_remove.add(chat_id)
                     continue
                # å°è¯•è·å–å¯¹è¯åç§°ä»¥æ£€æŸ¥å¯è®¿é—®æ€§
                chat_name = await self.translate_chat_id(chat_id)
                self._logger.info(f'Monitoring active for "{chat_name}" ({chat_id})')
            except EntityNotFoundError:
                 # å¦‚æœæ‰¾ä¸åˆ°å®ä½“æˆ–æ— æƒè®¿é—®ï¼Œæ ‡è®°ä¸ºç§»é™¤
                 self._logger.warning(f'Monitored chat_id {chat_id} not found/accessible, removing from monitor list.')
                 chats_to_remove.add(chat_id)
            except Exception as e:
                # å¤„ç†æ£€æŸ¥è¿‡ç¨‹ä¸­çš„å…¶ä»–å¼‚å¸¸ï¼ŒåŒæ ·æ ‡è®°ä¸ºç§»é™¤
                self._logger.error(f'Exception checking monitored chat {chat_id}: {e}, removing from monitor list.')
                chats_to_remove.add(chat_id)

        # æ‰§è¡Œç§»é™¤æ“ä½œ
        if chats_to_remove:
            for chat_id in chats_to_remove:
                self.monitored_chats.discard(chat_id) # ä»ç›‘æ§é›†åˆä¸­ç§»é™¤
                self.newest_msg.pop(chat_id, None) # ä»æœ€æ–°æ¶ˆæ¯ç¼“å­˜ä¸­ç§»é™¤
            self._logger.info(f'Removed {len(chats_to_remove)} chats from active monitoring.')

        # æ³¨å†Œ Telethon äº‹ä»¶é’©å­ä»¥æ¥æ”¶å®æ—¶æ¶ˆæ¯
        self._register_hooks()
        self._logger.info(f"Backend bot {self.id} started successfully.")


    def search(self, q: str, in_chats: Optional[List[int]], page_len: int, page_num: int, file_filter: str = "all") -> SearchResult:
        """å°†æœç´¢è¯·æ±‚è½¬å‘ç»™ Indexer"""
        # è®°å½•æœç´¢è¯·æ±‚çš„åŸºæœ¬ä¿¡æ¯
        self._logger.debug(f"Backend {self.id} search: q='{brief_content(q)}', chats={in_chats}, page={page_num}, filter={file_filter}")
        try:
            # è°ƒç”¨ Indexer çš„ search æ–¹æ³•æ‰§è¡Œæœç´¢
            result = self._indexer.search(q, in_chats, page_len, page_num, file_filter=file_filter)
            # è®°å½•æœç´¢ç»“æœçš„åŸºæœ¬ä¿¡æ¯
            self._logger.debug(f"Search returned {result.total_results} total hits, {len(result.hits)} on page {page_num}.")
            return result
        except Exception as e:
             # è®°å½•åç«¯æœç´¢æ‰§è¡Œå¤±è´¥çš„é”™è¯¯
             self._logger.error(f"Backend search execution failed for {self.id}: {e}", exc_info=True)
             # è¿”å›ä¸€ä¸ªç©ºçš„ SearchResult å¯¹è±¡ï¼Œè¡¨ç¤ºæœç´¢å¤±è´¥
             return SearchResult([], True, 0, page_num)


    def rand_msg(self) -> IndexMsg:
        """ä» Indexer è·å–éšæœºæ¶ˆæ¯"""
        try:
            # è°ƒç”¨ Indexer çš„æ–¹æ³•æ¥æ£€ç´¢éšæœºæ–‡æ¡£
            return self._indexer.retrieve_random_document()
        except IndexError:
            # å¦‚æœç´¢å¼•ä¸ºç©ºï¼Œåˆ™æŠ›å‡ºç‰¹å®šçš„ IndexError
            self._logger.warning("Cannot retrieve random message: Index is empty.")
            raise IndexError("Index is empty, cannot retrieve random message.")
        except Exception as e:
            # è®°å½•æ£€ç´¢éšæœºæ–‡æ¡£æ—¶å‘ç”Ÿçš„å…¶ä»–é”™è¯¯
            self._logger.error(f"Error retrieving random document: {e}", exc_info=True)
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†
            raise


    def is_empty(self, chat_id: Optional[int] = None) -> bool:
        """æ£€æŸ¥ç´¢å¼•æˆ–ç‰¹å®šå¯¹è¯æ˜¯å¦ä¸ºç©º"""
        try:
            # è°ƒç”¨ Indexer çš„ is_empty æ–¹æ³•
            return self._indexer.is_empty(chat_id)
        except Exception as e:
            # è®°å½•æ£€æŸ¥ç´¢å¼•æ˜¯å¦ä¸ºç©ºæ—¶å‘ç”Ÿçš„é”™è¯¯
            self._logger.error(f"Error checking index emptiness for {chat_id}: {e}")
            # åœ¨å‡ºé”™çš„æƒ…å†µä¸‹ï¼Œä¿å®ˆåœ°è¿”å› Trueï¼ˆè®¤ä¸ºç´¢å¼•ä¸ºç©ºï¼‰
            return True


    async def download_history(self, chat_id: Union[int, str], min_id: int, max_id: int, call_back: Optional[callable] = None):
        """
        ä¸‹è½½æŒ‡å®šå¯¹è¯çš„å†å²è®°å½•å¹¶æ·»åŠ åˆ°ç´¢å¼•ã€‚

        :param chat_id: åŸå§‹å¯¹è¯ ID æˆ–ç”¨æˆ·å/é“¾æ¥ã€‚
        :param min_id: è¦ä¸‹è½½çš„æœ€å°æ¶ˆæ¯ ID (ä¸åŒ…æ‹¬)ã€‚
        :param max_id: è¦ä¸‹è½½çš„æœ€å¤§æ¶ˆæ¯ ID (0 è¡¨ç¤ºæ— ä¸Šé™ï¼Œä¼šè·å–æ¯” min_id æ›´æ–°çš„æ‰€æœ‰æ¶ˆæ¯)ã€‚
        :param call_back: å¯é€‰çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºæŠ¥å‘Šè¿›åº¦ (æ¥æ”¶ cur_id, dl_count)ã€‚
        """
        task_name = f"DownloadHistory-{chat_id}"
        self._logger.info(f"Starting task: {task_name} (min={min_id}, max={max_id})")
        share_id = -1 # åˆå§‹åŒ–ä¸ºæ— æ•ˆå€¼
        entity = None # åˆå§‹åŒ–å®ä½“
        try:
            # å°è¯•ä½¿ç”¨åŸå§‹è¾“å…¥è·å–å®ä½“å’Œ share_id
            entity = await self.session.get_entity(chat_id)
            share_id = get_share_id(entity.id)
        except ValueError as e: # get_entity å¯èƒ½æŠ›å‡º ValueError
             self._logger.error(f"Could not find entity for '{chat_id}'. Error: {e}")
             raise EntityNotFoundError(f"æ— æ³•æ‰¾åˆ°å¯¹è¯å®ä½“: {chat_id}") from e
        except Exception as e:
            self._logger.error(f"Error resolving chat '{chat_id}' or getting share_id: {e}", exc_info=True)
            raise EntityNotFoundError(f"è§£æå¯¹è¯æ—¶å‡ºé”™: {chat_id}") from e

        task_name = f"DownloadHistory-{share_id}" # æ›´æ–°ä»»åŠ¡å
        self._logger.info(f'Downloading history for {share_id} (input="{chat_id}", min={min_id}, max={max_id})')
        # æ£€æŸ¥å¯¹è¯æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if share_id in self.excluded_chats:
            self._logger.warning(f"Skipping download for excluded chat {share_id}.")
            raise ValueError(f"å¯¹è¯ {share_id} å·²è¢«æ’é™¤ï¼Œæ— æ³•ä¸‹è½½ã€‚") # æŠ›å‡º ValueError è¡¨ç¤ºæ“ä½œä¸å…è®¸

        # --- ç›‘æ§åé¦ˆé€»è¾‘ ---
        is_newly_monitored = False
        if share_id not in self.monitored_chats:
            is_newly_monitored = True
            self.monitored_chats.add(share_id)
            # æ·»åŠ åˆ°ç›‘æ§åˆ—è¡¨çš„æ—¥å¿—åé¦ˆ
            self._logger.info(f"[Monitoring] Added chat {share_id} to monitored list during download request.")

        msg_list: List[IndexMsg] = [] # å­˜å‚¨ä» Telegram è·å–å¹¶å‡†å¤‡ç´¢å¼•çš„æ¶ˆæ¯
        downloaded_count: int = 0 # å®é™…æ„é€ äº† IndexMsg çš„æ¶ˆæ¯æ•°é‡
        processed_count: int = 0 # Telethon `iter_messages` è¿”å›çš„æ€»é¡¹ç›®æ•°
        newest_msg_in_batch: Optional[IndexMsg] = None # è®°å½•æ­¤æ‰¹æ¬¡ä¸­æœ€æ–°çš„æ¶ˆæ¯
        indexed_count_in_batch: int = 0

        try:
            # ä½¿ç”¨ Telethon å¼‚æ­¥è¿­ä»£æŒ‡å®šå¯¹è¯çš„æ¶ˆæ¯å†å²
            # ä¼ é€’è·å–åˆ°çš„ entity ç»™ iter_messages
            async for tg_message in self.session.iter_messages(entity=entity, min_id=min_id, max_id=max_id, limit=None, reverse=True): # reverse=True ç¡®ä¿ä»æ—§åˆ°æ–°å¤„ç†ï¼Œä¾¿äºç¡®å®š newest_msg
                processed_count += 1
                if not isinstance(tg_message, TgMessage): continue

                # ä½¿ç”¨ share_id æ„å»º URL å’Œ IndexMsg
                url = f'https://t.me/c/{share_id}/{tg_message.id}'
                sender = await self._get_sender_name(tg_message)
                post_time = tg_message.date
                if not isinstance(post_time, datetime):
                    self._logger.warning(f"Message {url} has invalid date type {type(post_time)}, using current time.")
                    post_time = datetime.now()

                msg_text, filename = '', None
                # åŒ…å«æ–‡ä»¶ç´¢å¼•é€»è¾‘
                if tg_message.file and hasattr(tg_message.file, 'name') and tg_message.file.name:
                    filename = tg_message.file.name
                    # åŒæ—¶è·å–å¯èƒ½çš„æ–‡ä»¶æ ‡é¢˜/è¯´æ˜
                    if tg_message.text: msg_text = escape_content(tg_message.text.strip())
                elif tg_message.text:
                    msg_text = escape_content(tg_message.text.strip())

                # åªæœ‰å½“æœ‰æ–‡æœ¬å†…å®¹æˆ–æ–‡ä»¶åæ—¶æ‰ç´¢å¼•
                if msg_text or filename:
                    try:
                        # IndexMsg ä½¿ç”¨ share_idï¼Œå¹¶åŒ…å« filename
                        msg = IndexMsg(content=msg_text or "", url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                        msg_list.append(msg)
                        downloaded_count += 1
                        # æ›´æ–°æ­¤æ‰¹æ¬¡ä¸­é‡åˆ°çš„æœ€æ–°æ¶ˆæ¯
                        newest_msg_in_batch = msg
                    except Exception as create_e:
                        self._logger.error(f"Error creating IndexMsg for {url}: {create_e}")
                # else: å¿½ç•¥æ²¡æœ‰æ–‡æœ¬å’Œæ–‡ä»¶åçš„æ¶ˆæ¯

                # è¿›åº¦å›è°ƒå’Œäº‹ä»¶å¾ªç¯é‡Šæ”¾
                if call_back and processed_count % 100 == 0:
                     try: await call_back(tg_message.id, downloaded_count)
                     except Exception as cb_e: self._logger.warning(f"Error in download callback: {cb_e}")
                if processed_count % 500 == 0:
                    self._logger.debug(f"Download progress for {share_id}: Processed {processed_count}, Indexable {downloaded_count}")
                    await asyncio.sleep(0.01) # é‡Šæ”¾äº‹ä»¶å¾ªç¯

            # --- å¤„ç†ä¸‹è½½é”™è¯¯ ---
        except telethon.errors.rpcerrorlist.ChannelPrivateError as e:
            self._logger.error(f"Permission denied for chat '{chat_id}' ({share_id}). Is the backend account a member? Error: {e}")
            self.monitored_chats.discard(share_id) # ç§»é™¤æ— æ³•è®¿é—®çš„å¯¹è¯
            if is_newly_monitored: self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to access error.")
            raise EntityNotFoundError(f"æ— æ³•è®¿é—®å¯¹è¯ '{chat_id}' ({share_id})ï¼Œè¯·ç¡®ä¿åç«¯è´¦å·æ˜¯å…¶æˆå‘˜ã€‚") from e
        except (telethon.errors.rpcerrorlist.ChatIdInvalidError, telethon.errors.rpcerrorlist.PeerIdInvalidError):
            self._logger.error(f"Chat ID '{chat_id}' ({share_id}) invalid or peer not found.")
            self.monitored_chats.discard(share_id)
            if is_newly_monitored: self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to invalid ID.")
            raise EntityNotFoundError(f"æ— æ•ˆå¯¹è¯ ID æˆ–æ— æ³•æ‰¾åˆ° Peer: '{chat_id}' ({share_id})")
        except ValueError as e:
             # Telethon çš„ get_entity æˆ– iter_messages å¯èƒ½åœ¨æ‰¾ä¸åˆ°å®ä½“æ—¶æŠ›å‡º ValueError
             if "Cannot find any entity corresponding to" in str(e) or "Could not find the input entity for" in str(e):
                 self._logger.error(f"Cannot find entity for chat '{chat_id}' ({share_id}). Error: {e}")
                 self.monitored_chats.discard(share_id)
                 if is_newly_monitored: self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to entity not found.")
                 raise EntityNotFoundError(f"æ— æ³•æ‰¾åˆ°å¯¹è¯å®ä½“: '{chat_id}' ({share_id})") from e
             else:
                 # å…¶ä»–ç±»å‹çš„ ValueError
                 self._logger.error(f"ValueError iterating messages for {share_id}: {e}", exc_info=True)
                 raise RuntimeError(f"ä¸‹è½½å¯¹è¯ {share_id} æ—¶å‘ç”Ÿå€¼é”™è¯¯") from e
        except Exception as e:
            self._logger.error(f"Error iterating messages for {share_id}: {e}", exc_info=True)
            # å¦‚æœåœ¨ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œä¹Ÿè€ƒè™‘ç§»é™¤ï¼ˆå¦‚æœåˆšæ·»åŠ çš„è¯ï¼‰
            if is_newly_monitored:
                self.monitored_chats.discard(share_id)
                self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to download error.")
            raise RuntimeError(f"ä¸‹è½½å¯¹è¯ {share_id} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯") from e

        # --- æ‰¹é‡å†™å…¥ç´¢å¼• ---
        self._logger.info(f'History fetch complete for {share_id}: {downloaded_count} messages to index out of {processed_count} processed.')
        if not msg_list:
            self._logger.info(f"No indexable messages found for chat {share_id} in the specified range.")
            # å¦‚æœæ˜¯æ–°ç›‘æ§çš„ä½†æ²¡ä¸‹è½½åˆ°æ¶ˆæ¯ï¼Œä»ç„¶ä¿ç•™åœ¨ç›‘æ§åˆ—è¡¨
            return

        writer: Optional[IndexWriter] = None
        try:
            # ä½¿ç”¨ä¼˜åŒ–åçš„æ‰¹é‡å†™å…¥æ¨¡å¼
            self._logger.info(f"Starting batch write for {len(msg_list)} messages from chat {share_id}...")
            # ä¸€æ¬¡æ€§è·å– writer
            writer = self._indexer.ix.writer()
            for i, msg in enumerate(msg_list):
                try:
                    # ç›´æ¥è°ƒç”¨ add_documentï¼Œä¼ é€’ writer
                    self._indexer.add_document(msg, writer=writer)
                    indexed_count_in_batch += 1
                    # å‡å°‘æ—¥å¿—é¢‘ç‡ï¼Œé¿å…åˆ·å±
                    if i > 0 and (i + 1) % 5000 == 0:
                        self._logger.debug(f"Batch write progress for {share_id}: {i+1}/{len(msg_list)} messages added...")
                        await asyncio.sleep(0.01) # çŸ­æš‚é‡Šæ”¾
                except Exception as add_e:
                    self._logger.error(f"Error adding document {msg.url} to batch writer: {add_e}")
            # å¾ªç¯ç»“æŸåæäº¤
            writer.commit()
            self._logger.info(f'Write index commit successful for {indexed_count_in_batch} messages from chat {share_id}')
            # æ›´æ–°è¯¥å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯ç¼“å­˜
            if newest_msg_in_batch:
                 # newest_msg_in_batch.chat_id å·²ç»æ˜¯ share_id
                 current_chat_id = newest_msg_in_batch.chat_id
                 # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²æœ‰è®°å½•ï¼Œä»¥åŠæ–°æ¶ˆæ¯æ˜¯å¦æ›´æ–°
                 if current_chat_id not in self.newest_msg or newest_msg_in_batch.post_time > self.newest_msg[current_chat_id].post_time:
                      self.newest_msg[current_chat_id] = newest_msg_in_batch
                      self._logger.debug(f"Updated newest msg cache for {current_chat_id} to {newest_msg_in_batch.url}")

        except writing.LockError:
            self._logger.error("Index is locked during batch write. Downloaded messages are lost for this batch.")
            if writer and not writer.is_closed:
                try: writer.cancel()
                except Exception as cancel_e: self._logger.error(f"Error cancelling writer after lock: {cancel_e}")
            # å¦‚æœæ˜¯å› ä¸ºé”é”™è¯¯å¯¼è‡´å†™å…¥å¤±è´¥ï¼Œå¹¶ä¸”æ˜¯åˆšæ·»åŠ çš„ç›‘æ§ï¼Œåˆ™ç§»é™¤
            if is_newly_monitored:
                 self.monitored_chats.discard(share_id)
                 self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to index lock during initial write.")
            raise RuntimeError("Index is locked, cannot write downloaded messages.")
        except Exception as e:
            self._logger.error(f"Error writing batch index for {share_id}: {e}", exc_info=True)
            if writer and not writer.is_closed:
                try: writer.cancel()
                except Exception as cancel_e: self._logger.error(f"Error cancelling writer after general error: {cancel_e}")
            # å¦‚æœæ˜¯å› ä¸ºå†™å…¥é”™è¯¯å¯¼è‡´å†™å…¥å¤±è´¥ï¼Œå¹¶ä¸”æ˜¯åˆšæ·»åŠ çš„ç›‘æ§ï¼Œåˆ™ç§»é™¤
            if is_newly_monitored:
                 self.monitored_chats.discard(share_id)
                 self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to index write error during initial write.")
            raise RuntimeError(f"å†™å…¥ç´¢å¼•æ—¶å‡ºé”™ for {share_id}")
        finally:
             # ç¡®ä¿ writer è¢«å…³é—­ï¼ˆå³ä½¿åœ¨ commit() ä¹‹åä¹Ÿéœ€è¦ï¼‰
             if writer and not writer.is_closed:
                 try:
                     # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œcommit å¯èƒ½æœªæ‰§è¡Œï¼Œcancel æ˜¯æ›´å®‰å…¨çš„é€‰æ‹©
                     writer.cancel() # æˆ–è€…æ ¹æ®æ˜¯å¦æœ‰å¼‚å¸¸å†³å®š commit/cancel
                 except Exception as final_cancel_e:
                     self._logger.error(f"Error ensuring writer closure: {final_cancel_e}")
             self._logger.info(f"Finished task: {task_name}")

    def clear(self, chat_ids: Optional[List[int]] = None):
        """
        æ¸…é™¤ç´¢å¼•æ•°æ®ã€‚

        :param chat_ids: å¯é€‰ï¼Œè¦æ¸…é™¤çš„ chat_id åˆ—è¡¨ (æ¥æ”¶ share_id)ã€‚å¦‚æœä¸º Noneï¼Œåˆ™æ¸…é™¤æ‰€æœ‰ç´¢å¼•ã€‚
        """
        if chat_ids is not None:
            # æ¸…é™¤æŒ‡å®šå¯¹è¯çš„æ•°æ®
            share_ids_to_clear = set(chat_ids) # å‡è®¾ä¼ å…¥çš„å°±æ˜¯ share_id åˆ—è¡¨

            if not share_ids_to_clear:
                self._logger.warning("No valid share IDs to clear.")
                return # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ IDï¼Œåˆ™ä¸æ‰§è¡Œä»»ä½•æ“ä½œ

            self._logger.info(f"Attempting to clear index data for chats: {share_ids_to_clear}")
            try:
                # ä½¿ç”¨ Whoosh writer æŒ‰ 'chat_id' å­—æ®µåˆ é™¤æ–‡æ¡£
                with self._indexer.ix.writer() as w:
                    total_deleted = 0
                    for share_id in share_ids_to_clear:
                        # ç¡®ä¿ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼çš„ share_id è¿›è¡Œ Term æŸ¥è¯¢
                        deleted_count = w.delete_by_term('chat_id', str(share_id))
                        total_deleted += deleted_count
                        # ä»ç›‘æ§åˆ—è¡¨å’Œæœ€æ–°æ¶ˆæ¯ç¼“å­˜ä¸­ç§»é™¤
                        if share_id in self.monitored_chats:
                           self.monitored_chats.discard(share_id)
                           self._logger.info(f'[Monitoring] Chat {share_id} removed from monitoring due to /clear command.')
                        if share_id in self.newest_msg:
                           del self.newest_msg[share_id]
                           self._logger.debug(f'Removed newest msg cache for cleared chat {share_id}')
                        if deleted_count > 0:
                            self._logger.info(f'Cleared {deleted_count} docs for chat {share_id}')
                        else:
                            self._logger.debug(f'No docs found to clear for chat {share_id}')
                    self._logger.info(f"Total {total_deleted} documents deleted for specified chats.")
            except writing.LockError:
                self._logger.error(f"Index locked. Failed to clear index for chats {share_ids_to_clear}.")
            except Exception as e:
                self._logger.error(f"Error clearing index for chats {share_ids_to_clear}: {e}", exc_info=True)
        else:
            # æ¸…é™¤æ‰€æœ‰ç´¢å¼•æ•°æ®
            self._logger.warning('Attempting to clear ALL index data.')
            try:
                # è°ƒç”¨ Indexer çš„ clear æ–¹æ³•
                self._indexer.clear()
                # æ¸…ç©ºç›‘æ§åˆ—è¡¨å’Œæœ€æ–°æ¶ˆæ¯ç¼“å­˜
                if self.monitored_chats:
                    self._logger.info(f"[Monitoring] Removing all {len(self.monitored_chats)} chats from monitoring due to /clear all.")
                    self.monitored_chats.clear()
                if self.newest_msg:
                    self._logger.debug(f"Clearing newest message cache for {len(self.newest_msg)} chats.")
                    self.newest_msg.clear()
                self._logger.info('Cleared all index data and stopped monitoring all chats.')
            except writing.LockError:
                self._logger.error("Index locked. Failed to clear all index data.")
            except Exception as e:
                self._logger.error(f"Error clearing all index data: {e}", exc_info=True)


    async def find_chat_id(self, q: str) -> List[int]:
        """ä½¿ç”¨ä¼šè¯æŸ¥æ‰¾åŒ¹é…å…³é”®è¯çš„å¯¹è¯ ID (è¿”å› share_id åˆ—è¡¨)"""
        try:
            # è°ƒç”¨ session çš„æ–¹æ³•æŸ¥æ‰¾å¯¹è¯ ID (å®ƒåº”è¯¥è¿”å› share_id)
            return await self.session.find_chat_id(q)
        except Exception as e:
            # è®°å½•æŸ¥æ‰¾å¯¹è¯ ID æ—¶çš„é”™è¯¯
            self._logger.error(f"Error finding chat id for '{q}': {e}")
            return [] # è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºæŸ¥æ‰¾å¤±è´¥


    async def get_index_status(self, length_limit: int = 4000) -> str:
        """è·å–åç«¯ç´¢å¼•çŠ¶æ€çš„æ–‡æœ¬æè¿° (ä¿®æ­£è®¡æ•°å’Œé”™è¯¯å¤„ç†é€»è¾‘, å¢åŠ æ—¥å¿—)"""
        cur_len = 0
        sb = [] # ä½¿ç”¨åˆ—è¡¨å­˜å‚¨å­—ç¬¦ä¸²ç‰‡æ®µï¼Œæœ€å join
        searcher = None # åˆå§‹åŒ– searcher å˜é‡

        # 1. è·å–æ€»æ–‡æ¡£æ•°
        total_docs = -1 # æ ‡è®°è·å–å¤±è´¥
        try:
            self._logger.debug("Attempting to get total document count from index...")
            # ç¡®ä¿ç´¢å¼•å­˜åœ¨ä¸”å¯è¯»
            if self._indexer and self._indexer.ix and not self._indexer.ix.is_empty():
                # å°è¯•æ‰“å¼€ searcher æ¥è·å–è®¡æ•°
                with self._indexer.ix.searcher() as s:
                    total_docs = s.doc_count_all() # è·å–æ‰€æœ‰æ–‡æ¡£æ•°
                self._logger.debug(f"Successfully retrieved total document count: {total_docs}")
            elif self._indexer and self._indexer.ix and self._indexer.ix.is_empty():
                total_docs = 0 # ç´¢å¼•å­˜åœ¨ä½†æ˜¯ç©ºçš„
                self._logger.debug("Index exists but is empty.")
            else:
                self._logger.error("Indexer or index object is not available.")
        except writing.LockError:
            self._logger.error(f"Index locked, failed get total doc count.")
        except Exception as e:
            self._logger.error(f"Failed get total doc count: {e}", exc_info=True) # Log with traceback
        # æ·»åŠ å¤´éƒ¨ä¿¡æ¯ (åç«¯ ID, ä¼šè¯å, æ€»æ¶ˆæ¯æ•°)
        sb.append(f'åç«¯ "{self.id}" (ä¼šè¯: "{self.session.name}") æ€»æ¶ˆæ¯: <b>{total_docs if total_docs >= 0 else "[è·å–å¤±è´¥]"}</b>\n\n')

        # å®šä¹‰è¶…å‡ºé•¿åº¦é™åˆ¶æ—¶çš„æç¤ºä¿¡æ¯
        overflow_msg = f'\n\n(éƒ¨åˆ†ä¿¡æ¯å› é•¿åº¦é™åˆ¶æœªæ˜¾ç¤º)'

        # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥æ·»åŠ æ–°å†…å®¹æ˜¯å¦ä¼šè¶…å‡ºé•¿åº¦é™åˆ¶
        def append_msg(msg_list: List[str]) -> bool:
            nonlocal cur_len
            new_len = sum(len(msg) for msg in msg_list)
            # è°ƒæ•´æ£€æŸ¥é€»è¾‘ï¼Œç¡®ä¿åœ¨æ¥è¿‘é™åˆ¶æ—¶åœæ­¢
            if cur_len + new_len > length_limit - len(overflow_msg) - 100: # å¢åŠ é¢„ç•™ç©ºé—´
                return True # è¿”å› True è¡¨ç¤ºè¶…å‡ºé™åˆ¶
            cur_len += new_len
            sb.extend(msg_list)
            return False # è¿”å› False è¡¨ç¤ºæœªè¶…å‡ºé™åˆ¶

        # 2. æ˜¾ç¤ºæ’é™¤åˆ—è¡¨
        # ç¡®ä¿ self.excluded_chats å­˜åœ¨ä¸”éç©º
        if hasattr(self, 'excluded_chats') and self.excluded_chats:
            excluded_list = sorted(list(self.excluded_chats))
            if append_msg([f'{len(excluded_list)} ä¸ªå¯¹è¯è¢«ç¦æ­¢ç´¢å¼•:\n']):
                sb.append(overflow_msg); return ''.join(sb)
            # ä½¿ç”¨ asyncio.gather å¹¶å‘è·å–åç§°
            tasks = [self.format_dialog_html(chat_id) for chat_id in excluded_list]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            for res in results:
                 if isinstance(res, Exception):
                     # è®°å½•é”™è¯¯ï¼Œä½†åˆ—è¡¨ä¸­å¯èƒ½éš¾ä»¥å¯¹åº”å› chat_id
                     self._logger.warning(f"Error formatting dialog HTML for excluded chat: {res}")
                     # å¯ä»¥æ·»åŠ ä¸€ä¸ªé€šç”¨é”™è¯¯æç¤ºï¼Œæˆ–è€…å¿½ç•¥æ ¼å¼åŒ–å¤±è´¥çš„é¡¹
                     if append_msg([f"- [è·å–åç§°å‡ºé”™]\n"]):
                         sb.append(overflow_msg); return ''.join(sb)
                 elif isinstance(res, str):
                      if append_msg([f'- {res}\n']):
                         sb.append(overflow_msg); return ''.join(sb)

            if sb and not sb[-1].endswith('\n\n'): sb.append('\n') # ç¡®ä¿æ®µè½é—´æœ‰ç©ºè¡Œ

        # 3. æ˜¾ç¤ºç›‘æ§åˆ—è¡¨å’Œè®¡æ•°
        # ç¡®ä¿ self.monitored_chats å­˜åœ¨
        monitored_chats_list = []
        if hasattr(self, 'monitored_chats'):
            # åªåŒ…æ‹¬æœªè¢«æ’é™¤çš„ç›‘æ§å¯¹è¯
            monitored_chats_list = sorted(list(self.monitored_chats - self.excluded_chats))

        if append_msg([f'æ€»è®¡ {len(monitored_chats_list)} ä¸ªå¯¹è¯è¢«åŠ å…¥äº†ç´¢å¼• (ä¸”æœªè¢«æ’é™¤):\n']):
            sb.append(overflow_msg); return ''.join(sb)

        # 4. è·å–æ¯ä¸ªç›‘æ§å¯¹è¯çš„è¯¦ç»†ä¿¡æ¯
        detailed_status_error = None
        if monitored_chats_list: # ä»…å½“æœ‰ç›‘æ§å¯¹è¯æ—¶æ‰å°è¯•æ‰“å¼€ searcher
            self._logger.debug(f"Getting status for {len(monitored_chats_list)} monitored chats.")
            try:
                 self._logger.debug("Attempting to open index searcher for chat counts...")
                 searcher = self._indexer.ix.searcher() # åœ¨å¾ªç¯å¤–æ‰“å¼€ searcher
                 self._logger.debug("Index searcher opened successfully.")

                 # å¹¶å‘è·å–åç§°
                 name_tasks = {}
                 for chat_id in monitored_chats_list:
                     name_tasks[chat_id] = asyncio.create_task(self.format_dialog_html(chat_id))

                 # ç­‰å¾…åç§°è·å–å®Œæˆ
                 name_results = await asyncio.gather(*name_tasks.values(), return_exceptions=True)
                 chat_html_map = {}
                 name_idx = 0
                 for chat_id in monitored_chats_list:
                      res = name_results[name_idx]
                      if isinstance(res, Exception):
                          chat_html_map[chat_id] = f"å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)"
                      else:
                          chat_html_map[chat_id] = res
                      name_idx += 1

                 # ä¾æ¬¡è·å–è®¡æ•°å¹¶ç»„åˆæ¶ˆæ¯
                 for chat_id in monitored_chats_list:
                     msg_for_chat = []
                     num = -1 # åˆå§‹åŒ–è®¡æ•°ä¸ºé”™è¯¯çŠ¶æ€ (-1)
                     chat_id_str = str(chat_id) # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
                     query = Term('chat_id', chat_id_str) # æ„å»º Term æŸ¥è¯¢

                     # å°è¯•è·å–è¯¥å¯¹è¯çš„æ–‡æ¡£è®¡æ•°
                     try:
                         # **ä½¿ç”¨ä¿®å¤åçš„æ–¹æ³•è·å–è®¡æ•°**
                         num = self._indexer.count_by_query(query=query)
                         self._logger.debug(f"Count for chat {chat_id_str} (query={query}): {num}")
                     except Exception as e: # æ•è·å…¶ä»–å¯èƒ½çš„é”™è¯¯
                         self._logger.error(f"Unexpected error counting docs for chat {chat_id_str} (query={query}): {e}", exc_info=True)
                         if not detailed_status_error: detailed_status_error = f"éƒ¨åˆ†å¯¹è¯è®¡æ•°å¤±è´¥ ({type(e).__name__}, e.g., chat {chat_id_str})"

                     # è·å–é¢„å…ˆæ ¼å¼åŒ–å¥½çš„ HTML åç§°
                     chat_html = chat_html_map.get(chat_id, f"å¯¹è¯ `{chat_id}` (æœªçŸ¥)")

                     # ç»„åˆå¯¹è¯ä¿¡æ¯å’Œè®¡æ•°ç»“æœ
                     count_str = "[è®¡æ•°å¤±è´¥]" if num < 0 else str(num)
                     msg_for_chat.append(f'- {chat_html} å…± {count_str} æ¡æ¶ˆæ¯\n')

                     # æ·»åŠ è¯¥å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯ä¿¡æ¯
                     if newest_msg := self.newest_msg.get(chat_id):
                         display_parts = []
                         if newest_msg.filename: display_parts.append(f"ğŸ“ {html.escape(brief_content(newest_msg.filename, 30))}") # é™åˆ¶æ–‡ä»¶åé•¿åº¦
                         if newest_msg.content: display_parts.append(html.escape(brief_content(newest_msg.content, 50))) # é™åˆ¶å†…å®¹é•¿åº¦
                         display = " ".join(display_parts) if display_parts else "(ç©ºæ¶ˆæ¯)"
                         time_str = newest_msg.post_time.strftime("%y-%m-%d %H:%M") if isinstance(newest_msg.post_time, datetime) else "[æœªçŸ¥æ—¶é—´]"
                         msg_for_chat.append(f'  æœ€æ–°: <a href="{html.escape(newest_msg.url)}">{display}</a> (@{time_str})\n')

                     # æ£€æŸ¥é•¿åº¦å¹¶å°è¯•æ·»åŠ 
                     if append_msg(msg_for_chat):
                         sb.append(overflow_msg); break # è¶…å‡ºåˆ™è·³å‡ºå¾ªç¯

                 if detailed_status_error and not (sb and sb[-1].endswith(overflow_msg)):
                     if append_msg([f"\nè­¦å‘Š: {detailed_status_error}\n"]):
                         sb.append(overflow_msg)

            except writing.LockError:
                 self._logger.error(f"Index locked, failed to open searcher for status.")
                 if append_msg(["\né”™è¯¯ï¼šç´¢å¼•è¢«é”å®šï¼Œæ— æ³•è·å–è¯¦ç»†å¯¹è¯çŠ¶æ€ã€‚\n"]):
                     sb.append(overflow_msg)
            except Exception as e:
                 self._logger.error(f"Failed to get detailed status (outside chat loop): {type(e).__name__}: {e}", exc_info=True)
                 if append_msg(["\né”™è¯¯ï¼šæ— æ³•è·å–è¯¦ç»†çŠ¶æ€ã€‚\n"]):
                     sb.append(overflow_msg)
            finally:
                # ç¡®ä¿ searcher å¯¹è±¡åœ¨ä½¿ç”¨åè¢«å…³é—­
                if searcher:
                    try:
                        searcher.close()
                        self._logger.debug("Searcher closed after getting index status.")
                    except Exception as close_e:
                        self._logger.error(f"Error closing searcher: {close_e}")
        # --- ç»“æŸè¯¦ç»†ä¿¡æ¯è·å– ---

        return ''.join(sb).strip() # è¿”å›å‰ç§»é™¤æœ«å°¾ç©ºç™½


    async def translate_chat_id(self, chat_id: int) -> str:
        """ä½¿ç”¨ä¼šè¯å°† Chat ID (share_id) ç¿»è¯‘ä¸ºåç§°"""
        try:
            # ç¡®ä¿ä¼ å…¥çš„æ˜¯æ•´æ•°
            chat_id_int = int(chat_id)
            return await self.session.translate_chat_id(chat_id_int)
        except (ValueError, TypeError):
             # å¤„ç† chat_id æ— æ³•è½¬æ¢ä¸ºæ•´æ•°çš„æƒ…å†µ
             self._logger.warning(f"Invalid chat_id type for translation: {chat_id} ({type(chat_id)})")
             raise EntityNotFoundError(f"æ— æ•ˆçš„ Chat ID æ ¼å¼: {chat_id}")
        except (telethon.errors.rpcerrorlist.ChannelPrivateError, telethon.errors.rpcerrorlist.ChatIdInvalidError) as e:
            self._logger.warning(f"Could not translate chat_id {chat_id}: {type(e).__name__}")
            raise EntityNotFoundError(f"æ— æ³•è®¿é—®æˆ–æ— æ•ˆ Chat ID: {chat_id}")
        except EntityNotFoundError:
            self._logger.warning(f"Entity not found for {chat_id} during translation.")
            raise
        except Exception as e:
            self._logger.error(f"Error translating chat_id {chat_id}: {e}", exc_info=True)
            raise EntityNotFoundError(f"è·å–å¯¹è¯ {chat_id} åç§°æ—¶å‡ºé”™") from e


    async def str_to_chat_id(self, chat: Union[str, int]) -> int:
        """å°†å­—ç¬¦ä¸²ï¼ˆç”¨æˆ·åã€é“¾æ¥æˆ– IDï¼‰æˆ–æ•´æ•° ID è½¬æ¢ä¸º share_id"""
        # é¦–å…ˆå¤„ç†æ•´æ•°è¾“å…¥
        if isinstance(chat, int):
            try:
                # å‡è®¾æ•´æ•°å·²ç»æ˜¯ peer_id æˆ– share_idï¼Œç›´æ¥ç”¨ get_share_id å¤„ç†
                return get_share_id(chat)
            except Exception as e_int:
                self._logger.error(f"Error converting int '{chat}' to share_id directly: {e_int}")
                raise EntityNotFoundError(f"è§£ææ•´æ•° ID '{chat}' æ—¶å‡ºé”™") from e_int

        # å¤„ç†å­—ç¬¦ä¸²è¾“å…¥
        elif isinstance(chat, str):
            chat_str = chat.strip()
            # å°è¯•ç›´æ¥å°†å­—ç¬¦ä¸²è½¬ä¸ºæ•´æ•° ID å¤„ç†
            try:
                return get_share_id(int(chat_str))
            except ValueError:
                # å¦‚æœä¸èƒ½ç›´æ¥è½¬ä¸ºæ•´æ•°ï¼Œåˆ™ä½¿ç”¨ session çš„æ–¹æ³•è§£æç”¨æˆ·åã€é“¾æ¥ç­‰
                try:
                    # session.str_to_chat_id åº”è¯¥è¿”å› peer_id
                    peer_id = await self.session.str_to_chat_id(chat_str)
                    # å°†è·å–çš„ peer_id è½¬æ¢ä¸º share_id
                    return get_share_id(peer_id)
                except EntityNotFoundError:
                    self._logger.warning(f"Entity not found for '{chat_str}' using session.")
                    raise # ç›´æ¥é‡æ–°æŠ›å‡º EntityNotFoundError
                except Exception as e_inner:
                    self._logger.error(f"Error converting '{chat_str}' to chat_id via session: {e_inner}", exc_info=True)
                    raise EntityNotFoundError(f"è§£æ '{chat_str}' æ—¶å‡ºé”™") from e_inner
        else:
             # å¤„ç†æ— æ•ˆè¾“å…¥ç±»å‹
             raise TypeError(f"Invalid input type for str_to_chat_id: {type(chat)}")


    async def format_dialog_html(self, chat_id: int) -> str:
        """æ ¼å¼åŒ–å¯¹è¯çš„ HTML é“¾æ¥å’Œåç§°ï¼ŒåŒ…å« share_id"""
        try:
            # ç¡®ä¿ chat_id æ˜¯æ•´æ•°
            chat_id_int = int(chat_id)
            name = await self.translate_chat_id(chat_id_int)
            esc_name = html.escape(name)
            # åˆ›å»ºæŒ‡å‘å¯¹è¯ç¬¬ä¸€æ¡æ¶ˆæ¯çš„é“¾æ¥ (é€šå¸¸ç”¨äºè·³è½¬åˆ°å¯¹è¯)
            return f'<a href="https://t.me/c/{chat_id_int}/1">{esc_name}</a> (`{chat_id_int}`)'
        except EntityNotFoundError:
            # å¦‚æœæ— æ³•ç¿»è¯‘åç§°ï¼Œä»ç„¶æ˜¾ç¤º ID
            return f'æœªçŸ¥å¯¹è¯ (`{chat_id}`)'
        except (ValueError, TypeError):
            # å¦‚æœ chat_id æ ¼å¼æ— æ•ˆ
            return f'æ— æ•ˆå¯¹è¯ ID (`{chat_id}`)'
        except Exception as e:
            # å…¶ä»–è·å–åç§°æ—¶çš„é”™è¯¯
            self._logger.warning(f"Error formatting html for {chat_id}: {e}")
            return f'å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)'


    def _should_monitor(self, chat_id: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç›‘æ§æ­¤å¯¹è¯çš„æ¶ˆæ¯ (åŸºäºé…ç½®å’Œç›‘æ§åˆ—è¡¨)"""
        try:
            # ä¼ å…¥çš„å¯èƒ½æ˜¯ peer_idï¼Œéœ€è¦è½¬ä¸º share_id
            share_id = get_share_id(chat_id)
            if share_id in self.excluded_chats: return False
            # å¦‚æœé…ç½®äº† monitor_all=Trueï¼Œæˆ–è€…è¯¥å¯¹è¯åœ¨å½“å‰çš„ç›‘æ§åˆ—è¡¨ä¸­ï¼Œåˆ™ç›‘æ§
            should = self._cfg.monitor_all or (share_id in self.monitored_chats)
            # self._logger.debug(f"Should monitor {share_id}? monitor_all={self._cfg.monitor_all}, in_list={share_id in self.monitored_chats} -> {should}")
            return should
        except Exception as e:
            self._logger.warning(f"Error determining monitor status for input chat {chat_id}: {e}")
            return False


    @staticmethod
    async def _get_sender_name(message: TgMessage) -> str:
        """è·å–æ¶ˆæ¯å‘é€è€…çš„åç§°ï¼ˆç”¨æˆ·æˆ–é¢‘é“/ç¾¤ç»„æ ‡é¢˜ï¼‰"""
        sender_name = ''
        try:
            # å°è¯•è·å–å‘é€è€…å®ä½“
            sender = await message.get_sender()
            if isinstance(sender, User):
                # å¦‚æœæ˜¯ç”¨æˆ·ï¼Œæ ¼å¼åŒ–åç§°
                sender_name = format_entity_name(sender)
            elif hasattr(sender, 'title'): # é€‚ç”¨äºé¢‘é“ã€ç¾¤ç»„ç­‰
                sender_name = sender.title
            elif hasattr(sender, 'username') and sender.username: # æœ€åçš„å¤‡é€‰ï¼šç”¨æˆ·å
                sender_name = f"@{sender.username}"
            # å¯ä»¥æ·»åŠ æ›´å¤šå¯¹ä¸åŒ Peer ç±»å‹çš„å¤„ç†
        except Exception as e:
            # è®°å½•è·å–å‘é€è€…åç§°å¤±è´¥çš„è°ƒè¯•ä¿¡æ¯
            logger.debug(f"Could not get sender name for message {getattr(message, 'id', 'N/A')} in chat {getattr(message, 'chat_id', 'N/A')}: {e}")
        # ç¡®ä¿è¿”å›å­—ç¬¦ä¸²ï¼Œå³ä½¿è·å–å¤±è´¥ä¹Ÿè¿”å›ç©ºå­—ç¬¦ä¸²
        return sender_name or ''

    def _register_hooks(self):
        """æ³¨å†Œ Telethon äº‹ä»¶é’©å­ï¼Œç”¨äºå®æ—¶æ¥æ”¶å’Œå¤„ç†æ¶ˆæ¯"""
        self._logger.info("Registering Telethon event handlers...")
        # ç”¨äºè·Ÿè¸ªå“ªäº› chat_id å·²ç»è¢«è®°å½•ä¸ºâ€œé¦–æ¬¡ç›‘æ§åˆ°â€
        _first_monitor_logged: Set[int] = set()

        # --- å¤„ç†æ–°æ¶ˆæ¯ ---
        @self.session.on(events.NewMessage())
        async def client_message_handler(event: events.NewMessage.Event):
            # åŸºç¡€æ£€æŸ¥ï¼šç¡®ä¿æœ‰ chat_id å’Œ message å¯¹è±¡
            message = event.message
            if not hasattr(event, 'chat_id') or event.chat_id is None or not message:
                self._logger.debug("Ignoring event with no chat_id or message object.")
                return

            try:
                # ä½¿ç”¨ event.chat_id (é€šå¸¸æ˜¯ peer_id) æ¥åˆ¤æ–­æ˜¯å¦ç›‘æ§
                if not self._should_monitor(event.chat_id):
                    # self._logger.debug(f"Ignoring message from non-monitored chat {event.chat_id}.")
                    return # ä¸å¤„ç†ä¸ç›‘æ§çš„å¯¹è¯

                # ä½¿ç”¨ get_share_id è½¬æ¢ä¸º share_id ç”¨äºå­˜å‚¨å’Œ URL
                share_id = get_share_id(event.chat_id)

                # å¦‚æœæ˜¯é¦–æ¬¡å¤„ç†è¿™ä¸ªç›‘æ§å¯¹è¯çš„æ¶ˆæ¯ï¼ˆä¸”æœªåœ¨æ—¥å¿—ä¸­è®°å½•è¿‡ï¼‰ï¼Œæ·»åŠ æ—¥å¿—
                if share_id not in _first_monitor_logged:
                     # æ£€æŸ¥å®ƒæ˜¯å¦ç¡®å®åœ¨ç›‘æ§åˆ—è¡¨æˆ– monitor_all=True
                     if share_id in self.monitored_chats or self._cfg.monitor_all:
                         self._logger.info(f"[Monitoring] First message processed from monitored chat {share_id} (Peer ID: {event.chat_id}).")
                         _first_monitor_logged.add(share_id)

                # --- æ¶ˆæ¯å¤„ç†é€»è¾‘ (åŒ…å«æ–‡ä»¶) ---
                url = f'https://t.me/c/{share_id}/{message.id}' # URL ä½¿ç”¨ share_id
                sender = await self._get_sender_name(message)
                post_time = message.date
                if not isinstance(post_time, datetime):
                    self._logger.warning(f"New message {url} has invalid date type {type(post_time)}, using current time.")
                    post_time = datetime.now()

                msg_text, filename = '', None
                if message.file and hasattr(message.file, 'name') and message.file.name:
                    filename = message.file.name
                    if message.text: msg_text = escape_content(message.text.strip())
                    self._logger.info(f'New file {url} from "{sender}" in chat {share_id}: "{filename}" Caption:"{brief_content(msg_text)}"')
                elif message.text:
                    msg_text = escape_content(message.text.strip())
                    # å¿½ç•¥çº¯ç©ºç™½æ¶ˆæ¯
                    if not msg_text: self._logger.debug(f"Ignoring empty/whitespace message {url} in {share_id}."); return
                    self._logger.info(f'New msg {url} from "{sender}" in chat {share_id}: "{brief_content(msg_text)}"')
                else:
                    # å¿½ç•¥æ—¢æ— æ–‡æœ¬ä¹Ÿæ— æœ‰æ•ˆæ–‡ä»¶åçš„æ¶ˆæ¯
                    self._logger.debug(f"Ignoring message {url} with no text or file in {share_id}.")
                    return

                # IndexMsg ä½¿ç”¨ share_id å¹¶åŒ…å« filename
                msg = IndexMsg(content=msg_text or "", url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                # æ›´æ–°æœ€æ–°æ¶ˆæ¯ç¼“å­˜ (ä½¿ç”¨ share_id ä½œä¸º key)
                if share_id not in self.newest_msg or msg.post_time >= self.newest_msg[share_id].post_time:
                    self.newest_msg[share_id] = msg
                    self._logger.debug(f"Updated newest cache for {share_id} to {url}")
                try:
                    # æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•
                    self._indexer.add_document(msg)
                except Exception as e:
                    self._logger.error(f"Error adding doc {url} to index: {e}", exc_info=True)
            except Exception as e:
                # é¡¶å±‚å¼‚å¸¸å¤„ç†
                chat_id_repr = getattr(event, 'chat_id', 'N/A')
                self._logger.error(f"Error processing new message in chat {chat_id_repr}: {e}", exc_info=True)

        # --- å¤„ç†æ¶ˆæ¯ç¼–è¾‘ ---
        @self.session.on(events.MessageEdited())
        async def client_message_update_handler(event: events.MessageEdited.Event):
            message = event.message
            if not hasattr(event, 'chat_id') or event.chat_id is None or not message: return

            try:
                # æ£€æŸ¥æ˜¯å¦ç›‘æ§æ­¤ chat_id
                if not self._should_monitor(event.chat_id): return
                # è·å– share_id
                share_id = get_share_id(event.chat_id)

                # ç¼–è¾‘å¤„ç†é€»è¾‘
                url = f'https://t.me/c/{share_id}/{message.id}' # URL ä½¿ç”¨ share_id
                new_msg_text = escape_content(message.text.strip()) if message.text else ''
                self._logger.info(f'Msg {url} edited in chat {share_id}. Checking for update...')

                try:
                    # ä½¿ç”¨ URL (å”¯ä¸€æ ‡è¯†) æŸ¥è¯¢æ—§æ–‡æ¡£
                    old_fields = self._indexer.get_document_fields(url=url)
                    if old_fields:
                        # æ£€æŸ¥å†…å®¹æ˜¯å¦å®é™…æ”¹å˜ (å¿½ç•¥æ–‡ä»¶å˜åŒ–)
                        if old_fields.get('content') == new_msg_text:
                            self._logger.debug(f"Edit event {url} has same text content, skipping index update.")
                            return

                        # å‡†å¤‡æ›´æ–°çš„å­—æ®µ
                        new_fields = old_fields.copy()
                        new_fields['content'] = new_msg_text
                        # ç¡®ä¿å…³é”®å­—æ®µå­˜åœ¨ä¸”ç±»å‹æ­£ç¡®
                        new_fields['chat_id'] = str(share_id) # æ›´æ–°ä¸ºå½“å‰ share_id (ä»¥é˜²ä¸‡ä¸€)
                        old_time = old_fields.get('post_time')
                        # ä¿ç•™åŸå§‹å‘å¸–æ—¶é—´ï¼Œé™¤éæ— æ³•è·å–æˆ–ç±»å‹é”™è¯¯
                        new_fields['post_time'] = old_time if isinstance(old_time, datetime) else (message.date or datetime.now())
                        if not isinstance(new_fields['post_time'], datetime): new_fields['post_time'] = datetime.now() # å†æ¬¡ç¡®ä¿æ˜¯ datetime
                        # å°è¯•ä¿ç•™åŸå§‹å‘é€è€…ï¼Œå¦åˆ™é‡æ–°è·å–
                        new_fields.setdefault('sender', old_fields.get('sender', await self._get_sender_name(message) or ''))
                        # ä¿ç•™æ–‡ä»¶åç­‰ä¿¡æ¯ï¼ˆé‡è¦ï¼šç¼–è¾‘äº‹ä»¶ä¸æ›´æ–°æ–‡ä»¶ä¿¡æ¯ï¼‰
                        new_fields['filename'] = old_fields.get('filename') # ä¿æŒæ—§çš„æ–‡ä»¶å
                        new_fields['has_file'] = old_fields.get('has_file', 0) # ä¿æŒæ—§çš„æ–‡ä»¶çŠ¶æ€
                        new_fields['url'] = url # ç¡®ä¿ URL æ­£ç¡®

                        # æ‰§è¡Œæ›¿æ¢æ“ä½œ
                        self._indexer.replace_document(url=url, new_fields=new_fields)
                        self._logger.info(f'Updated msg content in index for {url}')

                        # æ›´æ–°æœ€æ–°æ¶ˆæ¯ç¼“å­˜ï¼ˆå¦‚æœè¢«ç¼–è¾‘çš„æ˜¯æœ€æ–°æ¶ˆæ¯ï¼‰
                        if share_id in self.newest_msg and self.newest_msg[share_id].url == url:
                             try:
                                 # ä½¿ç”¨æ›´æ–°åçš„å­—æ®µé‡å»º IndexMsg ç”¨äºç¼“å­˜
                                 rebuilt_msg = IndexMsg(
                                     content=new_fields['content'], url=new_fields['url'],
                                     chat_id=share_id, # ç›´æ¥ä½¿ç”¨ share_id
                                     post_time=new_fields['post_time'], # å·²ç»æ˜¯ datetime
                                     sender=new_fields['sender'], filename=new_fields['filename']
                                 )
                                 self.newest_msg[share_id] = rebuilt_msg
                                 self._logger.debug(f"Updated newest cache content for {url}")
                             except (ValueError, KeyError, TypeError) as cache_e:
                                 self._logger.error(f"Error reconstructing IndexMsg for cache update {url}: {cache_e}. Fields: {new_fields}")
                    else:
                         # å¦‚æœæ—§æ–‡æ¡£ä¸å­˜åœ¨ï¼Œè§†ä¸ºæ–°æ¶ˆæ¯æ·»åŠ ï¼ˆä»…å½“æœ‰å†…å®¹æ—¶ï¼‰
                         self._logger.warning(f'Edited msg {url} not found in index. Adding as new message.')
                         if new_msg_text: # ç¡®ä¿ç¼–è¾‘åæœ‰æ–‡æœ¬å†…å®¹æ‰æ·»åŠ 
                             sender = await self._get_sender_name(message)
                             post_time = message.date or datetime.now()
                             if not isinstance(post_time, datetime): post_time = datetime.now()
                             # ç¼–è¾‘äº‹ä»¶é€šå¸¸ä¸å¸¦æ–‡ä»¶ä¿¡æ¯ï¼Œè®¾ä¸º None
                             filename = None

                             # ä½¿ç”¨ share_id åˆ›å»ºæ–°æ¶ˆæ¯
                             msg = IndexMsg(content=new_msg_text, url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                             self._indexer.add_document(msg)
                             # æ›´æ–°æœ€æ–°æ¶ˆæ¯ç¼“å­˜
                             if share_id not in self.newest_msg or msg.post_time >= self.newest_msg[share_id].post_time:
                                 self.newest_msg[share_id] = msg
                                 self._logger.debug(f"Added edited msg {url} as newest cache for {share_id}")
                         else:
                             self._logger.debug(f"Ignoring edited message {url} with empty content and not found in index.")
                except Exception as e:
                    # å¤„ç†æ›´æ–°/æ·»åŠ è¿‡ç¨‹ä¸­çš„é”™è¯¯
                    self._logger.error(f'Error updating/adding edited msg {url} in index: {e}', exc_info=True)
            except Exception as e:
                # å¤„ç†ç¼–è¾‘äº‹ä»¶é¡¶å±‚é”™è¯¯
                chat_id_repr = getattr(event, 'chat_id', 'N/A')
                self._logger.error(f"Error processing edited message in chat {chat_id_repr}: {e}", exc_info=True)

        # --- å¤„ç†æ¶ˆæ¯åˆ é™¤ ---
        @self.session.on(events.MessageDeleted())
        async def client_message_delete_handler(event: events.MessageDeleted.Event):
            # æ£€æŸ¥ chat_id
            if not hasattr(event, 'chat_id') or event.chat_id is None:
                self._logger.debug(f"Ignoring deletion event with no chat_id. Deleted IDs: {event.deleted_ids}")
                return
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ é™¤çš„ ID
            if not event.deleted_ids:
                 self._logger.debug(f"Ignoring deletion event with empty deleted_ids list in chat {event.chat_id}.")
                 return

            try:
                # æ£€æŸ¥æ˜¯å¦ç›‘æ§
                if not self._should_monitor(event.chat_id):
                    self._logger.debug(f"Ignoring deletion event from non-monitored chat {event.chat_id}. Deleted IDs: {event.deleted_ids}")
                    return
                # è·å– share_id
                share_id = get_share_id(event.chat_id)

                # åˆ é™¤å¤„ç†é€»è¾‘
                deleted_count_in_batch = 0
                # ä½¿ç”¨ share_id æ„å»º URL
                urls_to_delete = [f'https://t.me/c/{share_id}/{mid}' for mid in event.deleted_ids]
                self._logger.info(f"Processing deletion of {len(urls_to_delete)} message(s) in chat {share_id}: IDs {event.deleted_ids}")

                try:
                     # ä½¿ç”¨æ‰¹é‡å†™å…¥/åˆ é™¤æ¨¡å¼
                     with self._indexer.ix.writer() as writer:
                          for url in urls_to_delete:
                               # æ›´æ–°æœ€æ–°æ¶ˆæ¯ç¼“å­˜
                               if share_id in self.newest_msg and self.newest_msg[share_id].url == url:
                                    del self.newest_msg[share_id]
                                    self._logger.info(f"Removed newest cache for {share_id} due to deletion of {url}.")
                               # æ‰§è¡Œåˆ é™¤
                               try:
                                    # ä½¿ç”¨ URL åˆ é™¤
                                    count = writer.delete_by_term('url', url)
                                    if count > 0:
                                        deleted_count_in_batch += count
                                        self._logger.debug(f"Deleted msg {url} from index (count: {count}).")
                                    # else: æ¶ˆæ¯æœ¬å°±ä¸åœ¨ç´¢å¼•ä¸­ï¼Œæ— éœ€è®°å½•
                               except Exception as del_e:
                                    self._logger.error(f"Error deleting doc {url} from index within writer: {del_e}")
                     # æäº¤æ‰¹é‡åˆ é™¤
                     if deleted_count_in_batch > 0:
                         self._logger.info(f'Finished deleting {deleted_count_in_batch} msgs from index for chat {share_id}')
                     else:
                         self._logger.info(f"No matching messages found in index to delete for chat {share_id} batch (URLs: {urls_to_delete}).")
                except writing.LockError:
                    # å¤„ç†ç´¢å¼•é”å®šé”™è¯¯
                    self._logger.error(f"Index locked. Could not process deletions batch for {share_id}: {urls_to_delete}")
                except Exception as e:
                    # å¤„ç†å…¶ä»–æ‰¹é‡åˆ é™¤é”™è¯¯
                    self._logger.error(f"Error processing deletions batch for {share_id}: {e}", exc_info=True)
            except Exception as e:
                # å¤„ç†åˆ é™¤äº‹ä»¶é¡¶å±‚é”™è¯¯
                chat_id_repr = getattr(event, 'chat_id', 'N/A')
                self._logger.error(f"Error processing deleted event in chat {chat_id_repr}: {e}", exc_info=True)

        # æ ‡è®°äº‹ä»¶å¤„ç†å™¨æ³¨å†Œå®Œæˆï¼ˆç¡®ä¿åªåœ¨æ–¹æ³•æœ«å°¾æ‰§è¡Œä¸€æ¬¡ï¼‰
        self._logger.info("Telethon event handlers registered.")


    async def add_chats_to_monitoring(self, chat_ids: List[int]) -> Tuple[Set[int], Dict[int, str]]:
        """
        å°†æŒ‡å®šçš„å¯¹è¯ ID (share_id) æ·»åŠ åˆ°å®æ—¶ç›‘æ§åˆ—è¡¨ã€‚
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä»…åœ¨å†…å­˜ä¸­æ·»åŠ ï¼Œé‡å¯åè‹¥å¯¹è¯æ— ç´¢å¼•æ¶ˆæ¯ï¼Œç›‘æ§ä¼šä¸¢å¤±ã€‚

        :param chat_ids: éœ€è¦æ·»åŠ åˆ°ç›‘æ§çš„ share_id åˆ—è¡¨ã€‚
        :return: ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«:
                 - æˆåŠŸæ·»åŠ åˆ°ç›‘æ§åˆ—è¡¨çš„ share_id é›†åˆã€‚
                 - ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºæ·»åŠ å¤±è´¥çš„ share_idï¼Œå€¼ä¸ºå¤±è´¥åŸå› å­—ç¬¦ä¸²ã€‚
        """
        added_ok = set()
        add_failed = {}

        if not chat_ids:
            return added_ok, add_failed

        for chat_id in chat_ids:
            if not isinstance(chat_id, int):
                add_failed[chat_id] = "æ— æ•ˆçš„ ID ç±»å‹" # æŠ€æœ¯ä¸Š chat_id ä¼ å…¥æ˜¯ intï¼Œä½†ä¿æŒæ£€æŸ¥
                continue

            if chat_id in self.excluded_chats:
                add_failed[chat_id] = "å¯¹è¯å·²è¢«æ’é™¤"
                self._logger.info(f"[Monitoring] Ignoring request to monitor excluded chat {chat_id}")
                continue

            if chat_id in self.monitored_chats:
                add_failed[chat_id] = "å·²åœ¨ç›‘æ§ä¸­"
                self._logger.debug(f"[Monitoring] Chat {chat_id} is already monitored.")
                continue

            # å°è¯•æ·»åŠ åˆ°å†…å­˜ä¸­çš„ç›‘æ§åˆ—è¡¨
            self.monitored_chats.add(chat_id)
            added_ok.add(chat_id)
            self._logger.info(f"[Monitoring] Added chat {chat_id} to monitoring list via /monitor_chat.")
            # æ£€æŸ¥æ­¤ chat æ˜¯å¦å­˜åœ¨äº newest_msg ç¼“å­˜ä¸­ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•åŠ è½½
            if chat_id not in self.newest_msg:
                 self._logger.debug(f"Chat {chat_id} added to monitoring, checking for newest message in index...")
                 try:
                      result = self._indexer.search(q_str='*', in_chats=[chat_id], page_len=1, page_num=1, file_filter="all")
                      if result.hits:
                           self.newest_msg[chat_id] = result.hits[0].msg
                           self._logger.debug(f"Loaded newest message for newly monitored chat {chat_id}: {result.hits[0].msg.url}")
                 except Exception as e:
                      self._logger.warning(f"Failed to load newest message for newly monitored chat {chat_id}: {e}")


        return added_ok, add_failed
