# -*- coding: utf-8 -*-
import html
import asyncio # ç”¨äºå¼‚æ­¥æ“ä½œï¼Œå¦‚ sleep
from datetime import datetime
from typing import Optional, List, Set, Dict, Any, Union

import telethon.errors.rpcerrorlist
from telethon import events
from telethon.tl.patched import Message as TgMessage
from telethon.tl.types import User
from whoosh.query import Term # ç”¨äºæ„å»ºæŸ¥è¯¢
from whoosh import writing, searching # å¯¼å…¥ Whoosh ç›¸å…³æ¨¡å—
from whoosh.writing import IndexWriter, LockError # å†™å…¥å’Œé”é”™è¯¯

# é¡¹ç›®å†…å¯¼å…¥
from .indexer import Indexer, IndexMsg, SearchResult
from .common import CommonBotConfig, escape_content, get_share_id, get_logger, format_entity_name, brief_content, \
    EntityNotFoundError
from .session import ClientSession

# æ—¥å¿—è®°å½•å™¨
logger = get_logger('backend_bot')


class BackendBotConfig:
    """å­˜å‚¨ Backend Bot é…ç½®çš„ç±»"""
    def __init__(self, **kw: Any):
        self.monitor_all: bool = kw.get('monitor_all', False) # æ˜¯å¦ç›‘æ§æ‰€æœ‰åŠ å…¥çš„å¯¹è¯
        # åŸå§‹æ’é™¤åˆ—è¡¨ï¼Œå¯èƒ½åŒ…å«ç”¨æˆ·åæˆ– ID
        self._raw_exclude_chats: List[Union[int, str]] = kw.get('exclude_chats', [])
        # è§£æåçš„æ’é™¤åˆ—è¡¨ (ä»…å« share_id)
        self.excluded_chats: Set[int] = set()
        # åˆå§‹åŒ–æ—¶å°è¯•è§£ææ•´æ•° ID
        for chat_id_or_name in self._raw_exclude_chats:
            try: self.excluded_chats.add(get_share_id(int(chat_id_or_name)))
            except (ValueError, TypeError): pass # éæ•´æ•°ç•™ç»™ start() è§£æ


class BackendBot:
    """å¤„ç†ç´¢å¼•ã€ä¸‹è½½ã€åå°ç›‘æ§çš„æ ¸å¿ƒ Bot ç±»"""
    def __init__(self, common_cfg: CommonBotConfig, cfg: BackendBotConfig,
                 session: ClientSession, clean_db: bool, backend_id: str):
        """åˆå§‹åŒ– Backend Bot"""
        self.id: str = backend_id # åç«¯å®ä¾‹ ID
        self.session = session # åº•å±‚çš„ Telethon å®¢æˆ·ç«¯ä¼šè¯

        self._logger = get_logger(f'bot-backend:{backend_id}')
        self._cfg = cfg # åç«¯ç‰¹å®šé…ç½®
        # åˆå§‹åŒ– Indexer
        if clean_db: self._logger.info(f'Index will be cleaned for backend {backend_id}')
        try:
            self._indexer: Indexer = Indexer(common_cfg.index_dir / backend_id, clean_db)
        except ValueError as e: self._logger.critical(f"Indexer initialization failed: {e}"); raise
        except Exception as e: self._logger.critical(f"Unexpected error initializing indexer: {e}", exc_info=True); raise

        # åŠ è½½å·²ç›‘æ§çš„å¯¹è¯åˆ—è¡¨
        try:
            self.monitored_chats: Set[int] = self._indexer.list_indexed_chats()
            self._logger.info(f"Loaded {len(self.monitored_chats)} monitored chats from index")
        except Exception as e: self._logger.error(f"Failed to list indexed chats on startup: {e}", exc_info=True); self.monitored_chats = set()

        # å­˜å‚¨æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨ (åŒ…æ‹¬å¯åŠ¨æ—¶è§£æçš„)
        self.excluded_chats: Set[int] = cfg.excluded_chats
        self._raw_exclude_chats: List[Union[int, str]] = cfg._raw_exclude_chats # ä¿ç•™åŸå§‹é…ç½®
        # ç¼“å­˜æ¯ä¸ªç›‘æ§å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯
        self.newest_msg: Dict[int, IndexMsg] = dict()


    def _load_newest_messages_on_startup(self):
         """å¯åŠ¨æ—¶ä¸ºæ¯ä¸ªç›‘æ§çš„å¯¹è¯åŠ è½½æœ€æ–°æ¶ˆæ¯åˆ°ç¼“å­˜"""
         if not self.monitored_chats: return
         self._logger.info("Loading newest message for each monitored chat...")
         count = 0
         # è¿­ä»£å‰¯æœ¬ä»¥é˜²ä¿®æ”¹
         for chat_id in list(self.monitored_chats):
              if chat_id in self.excluded_chats: continue # è·³è¿‡æ’é™¤çš„å¯¹è¯
              try:
                   # æœç´¢è¯¥å¯¹è¯çš„æœ€æ–°ä¸€æ¡æ¶ˆæ¯ (æŒ‰æ—¶é—´å€’åºï¼Œå–ç¬¬ä¸€æ¡)
                   result = self._indexer.search(q_str='*', in_chats=[chat_id], page_len=1, page_num=1, file_filter="all")
                   if result.hits: self.newest_msg[chat_id] = result.hits[0].msg; count += 1
              except Exception as e: self._logger.warning(f"Failed to load newest message for chat {chat_id}: {e}")
         self._logger.info(f"Finished loading newest messages for {count} chats.")


    async def start(self):
        """å¯åŠ¨ Backend Bot"""
        self._logger.info(f'Starting backend bot {self.id}...')

        # è§£æé…ç½®ä¸­å¯èƒ½æ˜¯ç”¨æˆ·åçš„ exclude_chats
        resolved_excludes_in_cfg = set()
        for chat_id_or_name in self._raw_exclude_chats:
            # åªå¤„ç†éæ•°å­—å­—ç¬¦ä¸²
            if isinstance(chat_id_or_name, str) and not chat_id_or_name.lstrip('-').isdigit():
                 try:
                      share_id = await self.str_to_chat_id(chat_id_or_name) # å°è¯•è§£æ
                      resolved_excludes_in_cfg.add(share_id)
                      self._logger.info(f"Resolved exclude chat '{chat_id_or_name}' to ID {share_id}")
                 except EntityNotFoundError: self._logger.warning(f"Exclude chat '{chat_id_or_name}' not found, ignoring.")
                 except Exception as e: self._logger.error(f"Error resolving exclude chat '{chat_id_or_name}': {e}")

        # æ›´æ–°æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨
        self.excluded_chats.update(resolved_excludes_in_cfg)
        self._logger.info(f"Final excluded chats for backend {self.id}: {self.excluded_chats or 'None'}")

        # åŠ è½½æœ€æ–°æ¶ˆæ¯ç¼“å­˜
        self._load_newest_messages_on_startup()

        # å¯åŠ¨æ—¶æ£€æŸ¥ç›‘æ§çš„èŠå¤©æ˜¯å¦ä»ç„¶å¯è®¿é—®ï¼Œå¹¶ç§»é™¤æ— æ•ˆçš„
        chats_to_remove = set()
        for chat_id in list(self.monitored_chats): # è¿­ä»£å‰¯æœ¬
            try:
                if chat_id in self.excluded_chats: # å¦‚æœåœ¨æ’é™¤åˆ—è¡¨ï¼Œåˆ™ç§»é™¤ç›‘æ§
                     self._logger.info(f"Chat {chat_id} is excluded, removing from monitoring.")
                     chats_to_remove.add(chat_id); continue
                # å°è¯•è·å–åç§°ä»¥æ£€æŸ¥å¯è®¿é—®æ€§
                chat_name = await self.translate_chat_id(chat_id)
                self._logger.info(f'Monitoring active for "{chat_name}" ({chat_id})')
            except EntityNotFoundError: # æ— æ³•æ‰¾åˆ°æˆ–è®¿é—®
                 self._logger.warning(f'Monitored chat_id {chat_id} not found/accessible, removing from monitor list.')
                 chats_to_remove.add(chat_id)
            except Exception as e: # å…¶ä»–é”™è¯¯
                self._logger.error(f'Exception checking monitored chat {chat_id}: {e}, removing from monitor list.')
                chats_to_remove.add(chat_id)

        # æ‰§è¡Œç§»é™¤
        if chats_to_remove:
            for chat_id in chats_to_remove:
                self.monitored_chats.discard(chat_id)
                self.newest_msg.pop(chat_id, None) # ä»ç¼“å­˜ä¸­ç§»é™¤
            self._logger.info(f'Removed {len(chats_to_remove)} chats from active monitoring.')

        # æ³¨å†Œ Telethon äº‹ä»¶é’©å­
        self._register_hooks()
        self._logger.info(f"Backend bot {self.id} started successfully.")


    def search(self, q: str, in_chats: Optional[List[int]], page_len: int, page_num: int, file_filter: str = "all") -> SearchResult:
        """å°†æœç´¢è¯·æ±‚è½¬å‘ç»™ Indexer"""
        self._logger.debug(f"Backend {self.id} search: q='{brief_content(q)}', chats={in_chats}, page={page_num}, filter={file_filter}")
        try:
            # è°ƒç”¨ Indexer çš„ search æ–¹æ³•
            result = self._indexer.search(q, in_chats, page_len, page_num, file_filter=file_filter)
            self._logger.debug(f"Search returned {result.total_results} total hits, {len(result.hits)} on page {page_num}.")
            return result
        except Exception as e:
             self._logger.error(f"Backend search execution failed for {self.id}: {e}", exc_info=True)
             return SearchResult([], True, 0) # è¿”å›ç©ºç»“æœ


    def rand_msg(self) -> IndexMsg:
        """ä» Indexer è·å–éšæœºæ¶ˆæ¯"""
        try: return self._indexer.retrieve_random_document()
        except IndexError: raise IndexError("Index is empty, cannot retrieve random message.")
        except Exception as e: self._logger.error(f"Error retrieving random document: {e}", exc_info=True); raise


    def is_empty(self, chat_id: Optional[int] = None) -> bool:
        """æ£€æŸ¥ç´¢å¼•æˆ–ç‰¹å®šå¯¹è¯æ˜¯å¦ä¸ºç©º"""
        try: return self._indexer.is_empty(chat_id)
        except Exception as e: self._logger.error(f"Error checking index emptiness for {chat_id}: {e}"); return True # å‡ºé”™æ—¶è®¤ä¸ºç©º


    async def download_history(self, chat_id: int, min_id: int, max_id: int, call_back: Optional[callable] = None):
        """
        ä¸‹è½½æŒ‡å®šå¯¹è¯çš„å†å²è®°å½•å¹¶æ·»åŠ åˆ°ç´¢å¼•ã€‚

        :param chat_id: åŸå§‹å¯¹è¯ ID (å°†è¢«è½¬æ¢ä¸º share_id)ã€‚
        :param min_id: è¦ä¸‹è½½çš„æœ€å°æ¶ˆæ¯ ID (ä¸åŒ…æ‹¬)ã€‚
        :param max_id: è¦ä¸‹è½½çš„æœ€å¤§æ¶ˆæ¯ ID (ä¸åŒ…æ‹¬)ã€‚
        :param call_back: å¯é€‰çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºæŠ¥å‘Šè¿›åº¦ (æ¥æ”¶ cur_id, dl_count)ã€‚
        """
        try: share_id = get_share_id(chat_id) # è½¬æ¢ä¸º share_id
        except Exception as e: logger.error(f"Invalid chat_id format for download: {chat_id}, error: {e}"); raise EntityNotFoundError(f"æ— æ•ˆçš„å¯¹è¯ ID æ ¼å¼: {chat_id}")

        logger.info(f'Downloading history for {share_id} (raw_id={chat_id}, min={min_id}, max={max_id})')
        # è·³è¿‡å·²æ’é™¤çš„å¯¹è¯
        if share_id in self.excluded_chats: logger.warning(f"Skipping download for excluded chat {share_id}."); raise ValueError(f"å¯¹è¯ {share_id} å·²è¢«æ’é™¤ï¼Œæ— æ³•ä¸‹è½½ã€‚")
        # å¦‚æœå°šæœªç›‘æ§ï¼Œåˆ™æ·»åŠ åˆ°ç›‘æ§åˆ—è¡¨
        if share_id not in self.monitored_chats: self.monitored_chats.add(share_id); logger.info(f"Added chat {share_id} to monitored list.")

        msg_list: List[IndexMsg] = [] # å­˜å‚¨å¾…ç´¢å¼•çš„æ¶ˆæ¯
        downloaded_count: int = 0 # å®é™…å‡†å¤‡ç´¢å¼•çš„æ¶ˆæ¯æ•°
        processed_count: int = 0 # Telethon è¿”å›çš„æ€»æ¶ˆæ¯æ•°

        try:
            # å¼‚æ­¥è¿­ä»£æ¶ˆæ¯å†å²
            async for tg_message in self.session.iter_messages(entity=share_id, min_id=min_id, max_id=max_id, limit=None):
                processed_count += 1
                if not isinstance(tg_message, TgMessage): continue # è·³è¿‡éæ¶ˆæ¯ç±»å‹

                # æ„é€ æ¶ˆæ¯ URL
                url = f'https://t.me/c/{share_id}/{tg_message.id}'
                # è·å–å‘é€è€…åç§°
                sender = await self._get_sender_name(tg_message)
                # è·å–å‘é€æ—¶é—´ (ç¡®ä¿æ˜¯ datetime)
                post_time = tg_message.date
                if not isinstance(post_time, datetime): post_time = datetime.now()

                # æå–æ–‡æœ¬å’Œæ–‡ä»¶å
                msg_text, filename = '', None
                if tg_message.file and hasattr(tg_message.file, 'name') and tg_message.file.name:
                    filename = tg_message.file.name
                    if tg_message.text: msg_text = escape_content(tg_message.text.strip()) # æ–‡ä»¶å¯èƒ½é™„å¸¦æ ‡é¢˜
                elif tg_message.text:
                    msg_text = escape_content(tg_message.text.strip())

                # åªæœ‰åŒ…å«æ–‡æœ¬æˆ–æ–‡ä»¶åæ—¶æ‰åˆ›å»º IndexMsg
                if msg_text or filename:
                    try: msg = IndexMsg(content=msg_text or "", url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename); msg_list.append(msg); downloaded_count += 1
                    except Exception as create_e: logger.error(f"Error creating IndexMsg for {url}: {create_e}")

                # å®šæœŸè°ƒç”¨å›è°ƒå‡½æ•°æŠ¥å‘Šè¿›åº¦
                if call_back and processed_count % 100 == 0:
                     try: await call_back(tg_message.id, downloaded_count)
                     except Exception as cb_e: logger.warning(f"Error in download callback: {cb_e}")
                # å®šæœŸé‡Šæ”¾äº‹ä»¶å¾ªç¯ï¼Œé˜²æ­¢é•¿æ—¶é—´é˜»å¡
                if processed_count % 500 == 0: await asyncio.sleep(0.01)

        # å¤„ç† Telethon å¯èƒ½æŠ›å‡ºçš„é”™è¯¯
        except telethon.errors.rpcerrorlist.ChannelPrivateError as e: logger.error(f"Permission denied for chat {share_id}. Error: {e}"); self.monitored_chats.discard(share_id); raise EntityNotFoundError(f"æ— æ³•è®¿é—®å¯¹è¯ {chat_id}ï¼Œè¯·ç¡®ä¿åç«¯è´¦å·æ˜¯å…¶æˆå‘˜ã€‚") from e
        except (telethon.errors.rpcerrorlist.ChatIdInvalidError, telethon.errors.rpcerrorlist.PeerIdInvalidError): logger.error(f"Chat ID {share_id} (raw: {chat_id}) invalid."); self.monitored_chats.discard(share_id); raise EntityNotFoundError(f"æ— æ•ˆå¯¹è¯ ID æˆ–æ— æ³•æ‰¾åˆ° Peer: {chat_id}")
        except ValueError as e: # å¤„ç†æ— æ³•æ‰¾åˆ°å®ä½“é”™è¯¯
             if "Cannot find any entity corresponding to" in str(e) or "Could not find the input entity for" in str(e): logger.error(f"Cannot find entity for chat {share_id} (raw: {chat_id}). Error: {e}"); self.monitored_chats.discard(share_id); raise EntityNotFoundError(f"æ— æ³•æ‰¾åˆ°å¯¹è¯å®ä½“: {chat_id}") from e
             else: logger.error(f"ValueError iterating messages for {share_id}: {e}", exc_info=True); raise
        except Exception as e: logger.error(f"Error iterating messages for {share_id}: {e}", exc_info=True); raise RuntimeError(f"ä¸‹è½½å¯¹è¯ {share_id} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯") # æŠ›å‡ºé€šç”¨è¿è¡Œæ—¶é”™è¯¯

        logger.info(f'History fetch complete for {share_id}: {downloaded_count} messages to index out of {processed_count} processed.')
        if not msg_list: return # å¦‚æœæ²¡æœ‰å¯ç´¢å¼•çš„æ¶ˆæ¯ï¼Œç›´æ¥è¿”å›

        # --- æ‰¹é‡å†™å…¥ç´¢å¼• ---
        writer: Optional[IndexWriter] = None
        newest_msg_in_batch: Optional[IndexMsg] = None
        indexed_count_in_batch: int = 0
        try:
            writer = self._indexer.ix.writer() # è·å– writer
            for i, msg in enumerate(msg_list):
                try:
                    self._indexer.add_document(msg, writer); indexed_count_in_batch += 1
                    # è®°å½•æœ¬æ‰¹æ¬¡ä¸­æœ€æ–°çš„æ¶ˆæ¯
                    if newest_msg_in_batch is None or msg.post_time > newest_msg_in_batch.post_time: newest_msg_in_batch = msg
                    # æ‰¹é‡å†™å…¥æ—¶ä¹Ÿé¿å…é˜»å¡
                    if i % 1000 == 0: await asyncio.sleep(0.01)
                except Exception as add_e: logger.error(f"Error adding document {msg.url} to batch writer: {add_e}")
            writer.commit() # æäº¤å†™å…¥
            logger.info(f'Write index commit ok for {indexed_count_in_batch} messages from chat {share_id}')
            # æ›´æ–°è¯¥å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯ç¼“å­˜
            if newest_msg_in_batch:
                 current_chat_id = int(newest_msg_in_batch.chat_id)
                 if current_chat_id not in self.newest_msg or newest_msg_in_batch.post_time > self.newest_msg[current_chat_id].post_time:
                      self.newest_msg[current_chat_id] = newest_msg_in_batch
                      logger.debug(f"Updated newest msg cache for {current_chat_id} to {newest_msg_in_batch.url}")
        except writing.LockError: logger.error("Index is locked during batch write. Downloaded messages are lost."); raise RuntimeError("Index is locked, cannot write downloaded messages.")
        except Exception as e: logger.error(f"Error writing batch index for {share_id}: {e}", exc_info=True); raise RuntimeError(f"å†™å…¥ç´¢å¼•æ—¶å‡ºé”™ for {share_id}")


    def clear(self, chat_ids: Optional[List[int]] = None):
        """
        æ¸…é™¤ç´¢å¼•æ•°æ®ã€‚

        :param chat_ids: å¯é€‰ï¼Œè¦æ¸…é™¤çš„ chat_id åˆ—è¡¨ã€‚å¦‚æœä¸º Noneï¼Œåˆ™æ¸…é™¤æ‰€æœ‰ç´¢å¼•ã€‚
        """
        if chat_ids is not None:
            # æ¸…é™¤æŒ‡å®šå¯¹è¯çš„æ•°æ®
            share_ids_to_clear = {get_share_id(cid) for cid in chat_ids} # è½¬æ¢ä¸º share_id é›†åˆ
            try:
                with self._indexer.ix.writer() as w:
                    for share_id in share_ids_to_clear:
                        # æŒ‰ chat_id åˆ é™¤æ–‡æ¡£
                        deleted_count = w.delete_by_term('chat_id', str(share_id))
                        # åœæ­¢ç›‘æ§å¹¶æ¸…ç†ç¼“å­˜
                        self.monitored_chats.discard(share_id)
                        self.newest_msg.pop(share_id, None) # ä»ç¼“å­˜ç§»é™¤
                        logger.info(f'Cleared {deleted_count} docs and stopped monitoring chat {share_id}')
            except Exception as e: logger.error(f"Error clearing index for chats {share_ids_to_clear}: {e}")
        else:
            # æ¸…é™¤æ‰€æœ‰ç´¢å¼•æ•°æ®
            try:
                self._indexer.clear(); self.monitored_chats.clear(); self.newest_msg.clear()
                logger.info('Cleared all index data and stopped monitoring.')
            except Exception as e: logger.error(f"Error clearing all index data: {e}")


    async def find_chat_id(self, q: str) -> List[int]:
        """ä½¿ç”¨ä¼šè¯æŸ¥æ‰¾åŒ¹é…å…³é”®è¯çš„å¯¹è¯ ID"""
        try: return await self.session.find_chat_id(q)
        except Exception as e: logger.error(f"Error finding chat id for '{q}': {e}"); return []


    async def get_index_status(self, length_limit: int = 4000) -> str:
        """è·å–åç«¯ç´¢å¼•çŠ¶æ€çš„æ–‡æœ¬æè¿° (ä¿®æ­£è®¡æ•°å’Œé”™è¯¯å¤„ç†é€»è¾‘)"""
        cur_len = 0; sb = []; searcher = None # åˆå§‹åŒ– searcher
        try: total_docs = self._indexer.ix.doc_count()
        except Exception as e: total_docs = -1; logger.error(f"Failed get total doc count: {e}")
        sb.append(f'åç«¯ "{self.id}" (ä¼šè¯: "{self.session.name}") æ€»æ¶ˆæ¯: <b>{total_docs if total_docs >= 0 else "[è·å–å¤±è´¥]"}</b>\n\n')

        overflow_msg = f'\n\n(éƒ¨åˆ†ä¿¡æ¯å› é•¿åº¦é™åˆ¶æœªæ˜¾ç¤º)'
        def append_msg(msg_list: List[str]) -> bool: # è¾…åŠ©å‡½æ•°ï¼Œæ£€æŸ¥é•¿åº¦é™åˆ¶
            nonlocal cur_len; new_len = sum(len(msg) for msg in msg_list)
            if cur_len + new_len > length_limit - len(overflow_msg) - 50: return True
            cur_len += new_len; sb.extend(msg_list); return False

        # æ˜¾ç¤ºæ’é™¤åˆ—è¡¨
        if self.excluded_chats:
            excluded_list = sorted(list(self.excluded_chats))
            if append_msg([f'{len(excluded_list)} ä¸ªå¯¹è¯è¢«ç¦æ­¢ç´¢å¼•:\n']): sb.append(overflow_msg); return ''.join(sb)
            for chat_id in excluded_list:
                try: chat_html = await self.format_dialog_html(chat_id)
                except Exception: chat_html = f"å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)"
                if append_msg([f'- {chat_html}\n']): sb.append(overflow_msg); return ''.join(sb)
            if sb and sb[-1] != '\n\n': sb.append('\n')

        # æ˜¾ç¤ºç›‘æ§åˆ—è¡¨å’Œè®¡æ•°
        monitored_chats_list = sorted(list(self.monitored_chats))
        if append_msg([f'æ€»è®¡ {len(monitored_chats_list)} ä¸ªå¯¹è¯è¢«åŠ å…¥äº†ç´¢å¼•:\n']): sb.append(overflow_msg); return ''.join(sb)

        # --- è·å–æ¯ä¸ªç›‘æ§å¯¹è¯çš„è¯¦ç»†ä¿¡æ¯ ---
        try:
             searcher = self._indexer.ix.searcher() # åœ¨å¾ªç¯å¤–æ‰“å¼€ searcher
             for chat_id in monitored_chats_list:
                 msg_for_chat = []
                 num = -1 # åˆå§‹åŒ–è®¡æ•°ä¸ºé”™è¯¯çŠ¶æ€
                 chat_id_str = str(chat_id)
                 # å°è¯•è®¡æ•°
                 try:
                     query = Term('chat_id', chat_id_str)
                     num = searcher.doc_count(query=query) # ä½¿ç”¨ doc_count
                 except searching.SearchError as search_e: logger.error(f"Whoosh SearchError counting docs for chat {chat_id_str}: {search_e}", exc_info=True)
                 except Exception as e: logger.error(f"Unexpected error counting docs for chat {chat_id_str}: {e}", exc_info=True)
                 # å°è¯•è·å–åç§°
                 try: chat_html = await self.format_dialog_html(chat_id)
                 except Exception as name_e: logger.error(f"Error getting name for chat {chat_id}: {name_e}"); chat_html = f"å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)"
                 # ç»„åˆä¿¡æ¯
                 count_str = "[è®¡æ•°å¤±è´¥]" if num < 0 else str(num)
                 msg_for_chat.append(f'- {chat_html} å…± {count_str} æ¡æ¶ˆæ¯\n')
                 # æ·»åŠ æœ€æ–°æ¶ˆæ¯ä¿¡æ¯
                 if newest_msg := self.newest_msg.get(chat_id):
                     display = f"ğŸ“ {newest_msg.filename}" if newest_msg.filename else brief_content(newest_msg.content)
                     if newest_msg.filename and newest_msg.content: display += f" ({brief_content(newest_msg.content)})"
                     esc_display = html.escape(display or "(ç©º)")
                     msg_for_chat.append(f'  æœ€æ–°: <a href="{newest_msg.url}">{esc_display}</a> (@{newest_msg.post_time.strftime("%y-%m-%d %H:%M")})\n')
                 # æ£€æŸ¥é•¿åº¦å¹¶æ·»åŠ 
                 if append_msg(msg_for_chat): sb.append(overflow_msg); break
        except writing.LockError: # å¤„ç†æ‰“å¼€ searcher æ—¶çš„é”é”™è¯¯
             logger.error(f"Index locked, failed to open searcher for status.")
             if append_msg(["\né”™è¯¯ï¼šç´¢å¼•è¢«é”å®šï¼Œæ— æ³•è·å–è¯¦ç»†çŠ¶æ€ã€‚\n"]): sb.append(overflow_msg)
        except Exception as e: # å¤„ç†æ‰“å¼€ searcher æˆ–å…¶ä»–å¤–éƒ¨é”™è¯¯
             logger.error(f"Failed to open searcher or process chats for status: {e}", exc_info=True)
             if append_msg(["\né”™è¯¯ï¼šæ— æ³•è·å–è¯¦ç»†çŠ¶æ€ã€‚\n"]): sb.append(overflow_msg)
        finally:
            if searcher: searcher.close() # ç¡®ä¿ searcher è¢«å…³é—­
        # --- ç»“æŸè¯¦ç»†ä¿¡æ¯è·å– ---
        return ''.join(sb)


    async def translate_chat_id(self, chat_id: int) -> str:
        """ä½¿ç”¨ä¼šè¯å°† Chat ID ç¿»è¯‘ä¸ºåç§°"""
        try: return await self.session.translate_chat_id(int(chat_id))
        except (telethon.errors.rpcerrorlist.ChannelPrivateError, telethon.errors.rpcerrorlist.ChatIdInvalidError, ValueError, TypeError): raise EntityNotFoundError(f"æ— æ³•è®¿é—®æˆ–æ— æ•ˆ Chat ID: {chat_id}")
        except EntityNotFoundError: logger.warning(f"Entity not found for {chat_id}"); raise
        except Exception as e: logger.error(f"Error translating chat_id {chat_id}: {e}"); raise EntityNotFoundError(f"è·å–å¯¹è¯ {chat_id} åç§°æ—¶å‡ºé”™") from e


    async def str_to_chat_id(self, chat: str) -> int:
        """å°†å­—ç¬¦ä¸²ï¼ˆç”¨æˆ·åã€é“¾æ¥æˆ– IDï¼‰è½¬æ¢ä¸º share_id"""
        try:
            try: return get_share_id(int(chat)) # å°è¯•ç›´æ¥è½¬æ¢æ•´æ•° ID
            except ValueError: return get_share_id(await self.session.str_to_chat_id(chat)) # ä½¿ç”¨ä¼šè¯è§£æ
        except EntityNotFoundError: logger.warning(f"Entity not found for '{chat}'"); raise
        except Exception as e: logger.error(f"Error converting '{chat}' to chat_id: {e}"); raise EntityNotFoundError(f"è§£æ '{chat}' æ—¶å‡ºé”™") from e


    async def format_dialog_html(self, chat_id: int) -> str:
        """æ ¼å¼åŒ–å¯¹è¯çš„ HTML é“¾æ¥å’Œåç§°"""
        try: name = await self.translate_chat_id(int(chat_id)); esc_name = html.escape(name); return f'<a href="https://t.me/c/{chat_id}/1">{esc_name}</a> (`{chat_id}`)'
        except EntityNotFoundError: return f'æœªçŸ¥å¯¹è¯ (`{chat_id}`)' # å®ä½“æœªæ‰¾åˆ°
        except ValueError: return f'æ— æ•ˆå¯¹è¯ ID (`{chat_id}`)' # ID æ ¼å¼æ— æ•ˆ
        except Exception as e: logger.warning(f"Error formatting html for {chat_id}: {e}"); return f'å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)'


    def _should_monitor(self, chat_id: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç›‘æ§æ­¤å¯¹è¯çš„æ¶ˆæ¯"""
        try:
            share_id = get_share_id(chat_id)
            if share_id in self.excluded_chats: return False # åœ¨æ’é™¤åˆ—è¡¨åˆ™ä¸ç›‘æ§
            # å¦‚æœé…ç½®äº† monitor_allï¼Œæˆ–è€…è¯¥ chat_id åœ¨ç›‘æ§åˆ—è¡¨é‡Œï¼Œåˆ™ç›‘æ§
            return self._cfg.monitor_all or (share_id in self.monitored_chats)
        except Exception: return False # å‡ºé”™åˆ™ä¸ç›‘æ§


    @staticmethod
    async def _get_sender_name(message: TgMessage) -> str:
        """è·å–æ¶ˆæ¯å‘é€è€…çš„åç§°ï¼ˆç”¨æˆ·æˆ–é¢‘é“æ ‡é¢˜ï¼‰"""
        try:
            sender = await message.get_sender()
            if isinstance(sender, User): return format_entity_name(sender) # ç”¨æˆ·åˆ™æ ¼å¼åŒ–åç§°
            else: return getattr(sender, 'title', '') # é¢‘é“/ç¾¤ç»„åˆ™å–æ ‡é¢˜
        except Exception: return '' # å‡ºé”™è¿”å›ç©º


    def _register_hooks(self):
        """æ³¨å†Œ Telethon äº‹ä»¶é’©å­ï¼Œç”¨äºå®æ—¶æ¥æ”¶å’Œå¤„ç†æ¶ˆæ¯"""

        # å¤„ç†æ–°æ¶ˆæ¯
        @self.session.on(events.NewMessage())
        async def client_message_handler(event: events.NewMessage.Event):
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç›‘æ§æ­¤å¯¹è¯
            if not hasattr(event, 'chat_id') or event.chat_id is None or not self._should_monitor(event.chat_id): return
            try:
                share_id = get_share_id(event.chat_id); url = f'https://t.me/c/{share_id}/{event.id}'
                sender = await self._get_sender_name(event.message); post_time = event.message.date
                if not isinstance(post_time, datetime): post_time = datetime.now()

                # æå–æ–‡æœ¬å’Œæ–‡ä»¶å
                msg_text, filename = '', None
                if event.message.file and hasattr(event.message.file, 'name') and event.message.file.name:
                    filename = event.message.file.name
                    if event.message.text: msg_text = escape_content(event.message.text.strip())
                    logger.info(f'New file {url} from "{sender}": "{filename}" Cap:"{brief_content(msg_text)}"')
                elif event.message.text:
                    msg_text = escape_content(event.message.text.strip())
                    if not msg_text.strip(): return # å¿½ç•¥çº¯ç©ºç™½æ¶ˆæ¯
                    logger.info(f'New msg {url} from "{sender}": "{brief_content(msg_text)}"')
                else: return # å¿½ç•¥æ—¢æ— æ–‡æœ¬ä¹Ÿæ— æ–‡ä»¶çš„æ¶ˆæ¯

                # åˆ›å»º IndexMsg å¹¶æ·»åŠ åˆ°ç´¢å¼•
                msg = IndexMsg(content=msg_text or "", url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                # æ›´æ–°æœ€æ–°æ¶ˆæ¯ç¼“å­˜
                if share_id not in self.newest_msg or msg.post_time > self.newest_msg[share_id].post_time: self.newest_msg[share_id] = msg; logger.debug(f"Updated newest cache {share_id} to {url}")
                try: self._indexer.add_document(msg) # æ·»åŠ åˆ°ç´¢å¼•
                except Exception as e: logger.error(f"Error adding doc {url} to index: {e}")
            except Exception as e: logger.error(f"Error processing new message in chat {event.chat_id}: {e}", exc_info=True)

        # å¤„ç†æ¶ˆæ¯ç¼–è¾‘
        @self.session.on(events.MessageEdited())
        async def client_message_update_handler(event: events.MessageEdited.Event):
            if not hasattr(event, 'chat_id') or event.chat_id is None or not self._should_monitor(event.chat_id): return
            try:
                share_id = get_share_id(event.chat_id); url = f'https://t.me/c/{share_id}/{event.id}'
                new_msg_text = escape_content(event.message.text.strip()) if event.message.text else ''
                logger.info(f'Msg {url} edited. Checking for update...')
                try:
                    old_fields = self._indexer.get_document_fields(url=url)
                    if old_fields:
                        # å¦‚æœå†…å®¹æœªå˜ï¼Œåˆ™è·³è¿‡
                        if old_fields.get('content') == new_msg_text: logger.debug(f"Edit event {url} same content, skipping."); return
                        # å‡†å¤‡æ›´æ–°çš„å­—æ®µ
                        new_fields = old_fields.copy(); new_fields['content'] = new_msg_text or ""
                        # ç¡®ä¿å…¶ä»–å­—æ®µå­˜åœ¨ (å°½é‡ä½¿ç”¨æ—§å€¼)
                        new_fields.setdefault('chat_id', str(share_id))
                        new_fields.setdefault('post_time', old_fields.get('post_time', event.message.date or datetime.now()))
                        new_fields.setdefault('sender', old_fields.get('sender', await self._get_sender_name(event.message) or ''))
                        new_fields.setdefault('filename', old_fields.get('filename', None))
                        new_fields.setdefault('url', url)
                        new_fields['has_file'] = 1 if new_fields.get('filename') else 0 # é‡æ–°è®¡ç®—
                        # æ›¿æ¢æ–‡æ¡£
                        self._indexer.replace_document(url=url, new_fields=new_fields)
                        logger.info(f'Updated msg content in index for {url}')
                        # å¦‚æœæ˜¯æœ€æ–°æ¶ˆæ¯ï¼Œæ›´æ–°ç¼“å­˜
                        if share_id in self.newest_msg and self.newest_msg[share_id].url == url:
                             try: self.newest_msg[share_id] = IndexMsg(**new_fields); logger.debug(f"Updated newest cache content for {url}")
                             except Exception as cache_e: logger.error(f"Error reconstructing IndexMsg for cache update {url}: {cache_e}")
                    else:
                         # å¦‚æœç¼–è¾‘çš„æ¶ˆæ¯ä¸åœ¨ç´¢å¼•ä¸­ï¼Œåˆ™ä½œä¸ºæ–°æ¶ˆæ¯æ·»åŠ 
                         logger.warning(f'Edited msg {url} not found in index. Adding as new message.')
                         sender = await self._get_sender_name(event.message); post_time = event.message.date or datetime.now(); filename = None # å‡è®¾ç¼–è¾‘ä¸æ”¹å˜æ–‡ä»¶
                         if not isinstance(post_time, datetime): post_time = datetime.now()
                         msg = IndexMsg(content=new_msg_text or "", url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                         self._indexer.add_document(msg)
                         # æ›´æ–°æœ€æ–°æ¶ˆæ¯ç¼“å­˜
                         if share_id not in self.newest_msg or msg.post_time > self.newest_msg[share_id].post_time: self.newest_msg[share_id] = msg; logger.debug(f"Added edited msg {url} as newest cache for {share_id}")
                except Exception as e: logger.error(f'Error updating edited msg {url} in index: {e}', exc_info=True)
            except Exception as e: logger.error(f"Error processing edited message in chat {event.chat_id}: {e}", exc_info=True)

        # å¤„ç†æ¶ˆæ¯åˆ é™¤
        @self.session.on(events.MessageDeleted())
        async def client_message_delete_handler(event: events.MessageDeleted.Event):
            if not hasattr(event, 'chat_id') or event.chat_id is None or not self._should_monitor(event.chat_id):
                 logger.debug(f"Ignoring deletion event without valid/monitored chat_id. Deleted IDs: {event.deleted_ids}")
                 return
            try:
                share_id = get_share_id(event.chat_id)
                deleted_count = 0
                urls = [f'https://t.me/c/{share_id}/{mid}' for mid in event.deleted_ids]
                try:
                     # æ‰¹é‡åˆ é™¤
                     with self._indexer.ix.writer() as writer:
                          for url in urls:
                               # å¦‚æœåˆ é™¤çš„æ˜¯æœ€æ–°æ¶ˆæ¯ï¼Œæ¸…ç†ç¼“å­˜
                               if share_id in self.newest_msg and self.newest_msg[share_id].url == url:
                                    del self.newest_msg[share_id]
                                    logger.info(f"Removed newest cache for {share_id} due to deletion of {url}.")
                               try:
                                    count = writer.delete_by_term('url', url) # æŒ‰ URL åˆ é™¤
                                    if count > 0: deleted_count += count; logger.info(f"Deleted msg {url} from index.")
                               except Exception as del_e: logger.error(f"Error deleting doc {url} from index: {del_e}")
                     if deleted_count > 0: logger.info(f'Finished deleting {deleted_count} msgs from index for chat {share_id}')
                except Exception as e: logger.error(f"Error processing deletions batch for {share_id}: {e}")
            except Exception as e: logger.error(f"Error processing deleted event in chat {event.chat_id}: {e}", exc_info=True)
