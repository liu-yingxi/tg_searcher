# -*- coding: utf-8 -*-
import html
import asyncio # ç”¨äºå¼‚æ­¥æ“ä½œï¼Œå¦‚ sleep
from datetime import datetime
from typing import Optional, List, Set, Dict, Any, Union

import telethon.errors.rpcerrorlist
from telethon import events
from telethon.tl.patched import Message as TgMessage
from telethon.tl.types import User
from whoosh.query import Term # ç”¨äºæ„å»ºæŸ¥è¯¢
from whoosh import writing, searching # å¯¼å…¥ Whoosh ç›¸å…³æ¨¡å— (ç¡®ä¿ searching è¢«å¯¼å…¥)
from whoosh.writing import IndexWriter, LockError # å†™å…¥å’Œé”é”™è¯¯

# é¡¹ç›®å†…å¯¼å…¥
from .indexer import Indexer, IndexMsg, SearchResult
from .common import CommonBotConfig, escape_content, get_share_id, get_logger, format_entity_name, brief_content, \
    EntityNotFoundError
from .session import ClientSession

# æ—¥å¿—è®°å½•å™¨
# æ³¨æ„ï¼šè¿™é‡Œçš„ get_logger è¿”å›çš„æ˜¯å·²é…ç½®çš„ logger å®ä¾‹
logger = get_logger('backend_bot') # logger åœ¨æ¨¡å—çº§åˆ«å®šä¹‰ï¼Œæ‰€æœ‰å®ä¾‹å…±äº«


class BackendBotConfig:
    """å­˜å‚¨ Backend Bot é…ç½®çš„ç±»"""
    def __init__(self, **kw: Any):
        self.monitor_all: bool = kw.get('monitor_all', False) # æ˜¯å¦ç›‘æ§æ‰€æœ‰åŠ å…¥çš„å¯¹è¯
        # åŸå§‹æ’é™¤åˆ—è¡¨ï¼Œå¯èƒ½åŒ…å«ç”¨æˆ·åæˆ– ID
        self._raw_exclude_chats: List[Union[int, str]] = kw.get('exclude_chats', [])
        # è§£æåçš„æ’é™¤åˆ—è¡¨ (ä»…å« share_id)
        self.excluded_chats: Set[int] = set()
        # åˆå§‹åŒ–æ—¶å°è¯•è§£ææ•´æ•° ID
        for chat_id_or_name in self._raw_exclude_chats:
            try: self.excluded_chats.add(get_share_id(int(chat_id_or_name)))
            except (ValueError, TypeError): pass # éæ•´æ•°ç•™ç»™ start() è§£æ


class BackendBot:
    """å¤„ç†ç´¢å¼•ã€ä¸‹è½½ã€åå°ç›‘æ§çš„æ ¸å¿ƒ Bot ç±»"""
    def __init__(self, common_cfg: CommonBotConfig, cfg: BackendBotConfig,
                 session: ClientSession, clean_db: bool, backend_id: str):
        """åˆå§‹åŒ– Backend Bot"""
        self.id: str = backend_id # åç«¯å®ä¾‹ ID
        self.session = session # åº•å±‚çš„ Telethon å®¢æˆ·ç«¯ä¼šè¯

        # ä½¿ç”¨ç‰¹å®šäºæ­¤åç«¯å®ä¾‹çš„ logger
        self._logger = get_logger(f'bot-backend:{backend_id}')
        self._cfg = cfg # åç«¯ç‰¹å®šé…ç½®
        # åˆå§‹åŒ– Indexer
        if clean_db: self._logger.info(f'Index will be cleaned for backend {backend_id}')
        try:
            self._indexer: Indexer = Indexer(common_cfg.index_dir / backend_id, clean_db)
        except ValueError as e: self._logger.critical(f"Indexer initialization failed: {e}"); raise
        except Exception as e: self._logger.critical(f"Unexpected error initializing indexer: {e}", exc_info=True); raise

        # åŠ è½½å·²ç›‘æ§çš„å¯¹è¯åˆ—è¡¨
        try:
            # ä»ç´¢å¼•ä¸­åŠ è½½å·²ç›‘æ§çš„å¯¹è¯ ID
            self.monitored_chats: Set[int] = self._indexer.list_indexed_chats()
            self._logger.info(f"Loaded {len(self.monitored_chats)} monitored chats from index")
        except Exception as e:
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåˆå§‹åŒ–ä¸ºç©ºé›†åˆå¹¶è®°å½•é”™è¯¯
            self._logger.error(f"Failed to list indexed chats on startup: {e}", exc_info=True)
            self.monitored_chats = set()

        # å­˜å‚¨æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨ (åŒ…æ‹¬å¯åŠ¨æ—¶è§£æçš„)
        self.excluded_chats: Set[int] = cfg.excluded_chats
        self._raw_exclude_chats: List[Union[int, str]] = cfg._raw_exclude_chats # ä¿ç•™åŸå§‹é…ç½®
        # ç¼“å­˜æ¯ä¸ªç›‘æ§å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯ {chat_id: IndexMsg}
        self.newest_msg: Dict[int, IndexMsg] = dict()
        # è·Ÿè¸ªåå°ä»»åŠ¡ï¼Œä¾‹å¦‚ä¸‹è½½å†å²è®°å½•
        self._background_tasks: Set[asyncio.Task] = set()


    def _load_newest_messages_on_startup(self):
         """å¯åŠ¨æ—¶ä¸ºæ¯ä¸ªç›‘æ§çš„å¯¹è¯åŠ è½½æœ€æ–°æ¶ˆæ¯åˆ°ç¼“å­˜"""
         if not self.monitored_chats:
             self._logger.info("No monitored chats found in index, skipping loading newest messages.")
             return
         self._logger.info("Loading newest message for each monitored chat...")
         count = 0
         # è¿­ä»£ monitored_chats çš„å‰¯æœ¬ï¼Œä»¥é˜²åœ¨åŠ è½½æœŸé—´åˆ—è¡¨è¢«ä¿®æ”¹
         for chat_id in list(self.monitored_chats):
              # è·³è¿‡å·²åœ¨æ’é™¤åˆ—è¡¨ä¸­çš„å¯¹è¯
              if chat_id in self.excluded_chats:
                  self._logger.debug(f"Skipping loading newest message for excluded chat {chat_id}.")
                  continue
              try:
                   # æœç´¢è¯¥å¯¹è¯çš„æœ€æ–°ä¸€æ¡æ¶ˆæ¯
                   # ä½¿ç”¨ q_str='*' åŒ¹é…æ‰€æœ‰æ–‡æ¡£ï¼ŒæŒ‰æ—¶é—´å€’åºï¼Œåªå–ç¬¬ä¸€æ¡
                   result = self._indexer.search(q_str='*', in_chats=[chat_id], page_len=1, page_num=1, file_filter="all")
                   if result.hits:
                       self.newest_msg[chat_id] = result.hits[0].msg
                       count += 1
                       self._logger.debug(f"Loaded newest message for chat {chat_id}: {result.hits[0].msg.url}")
                   else:
                       self._logger.debug(f"No messages found in index for chat {chat_id} to load as newest.")
              except Exception as e:
                  # è®°å½•åŠ è½½ç‰¹å®šå¯¹è¯æœ€æ–°æ¶ˆæ¯æ—¶çš„é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹
                  self._logger.warning(f"Failed to load newest message for chat {chat_id}: {e}")
         self._logger.info(f"Finished loading newest messages for {count} monitored (and not excluded) chats.")


    async def start(self):
        """å¯åŠ¨ Backend Bot"""
        self._logger.info(f'Starting backend bot {self.id}...')

        # è§£æé…ç½®ä¸­å¯èƒ½æ˜¯ç”¨æˆ·åçš„ exclude_chats
        resolved_excludes_in_cfg = set()
        for chat_id_or_name in self._raw_exclude_chats:
            # åªå¤„ç†éæ•°å­—å­—ç¬¦ä¸²ï¼Œå°è¯•å°†å…¶è§£æä¸º share_id
            if isinstance(chat_id_or_name, str) and not chat_id_or_name.lstrip('-').isdigit():
                 try:
                      share_id = await self.str_to_chat_id(chat_id_or_name) # å°è¯•è§£æ
                      resolved_excludes_in_cfg.add(share_id)
                      self._logger.info(f"Resolved exclude chat '{chat_id_or_name}' to ID {share_id}")
                 except EntityNotFoundError:
                     # å¦‚æœæ‰¾ä¸åˆ°å®ä½“ï¼Œè®°å½•è­¦å‘Šå¹¶å¿½ç•¥
                     self._logger.warning(f"Exclude chat '{chat_id_or_name}' not found, ignoring.")
                 except Exception as e:
                     # è®°å½•è§£æè¿‡ç¨‹ä¸­çš„å…¶ä»–é”™è¯¯
                     self._logger.error(f"Error resolving exclude chat '{chat_id_or_name}': {e}")

        # æ›´æ–°æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨ï¼Œåˆå¹¶æ¥è‡ªé…ç½®çš„è§£æç»“æœ
        self.excluded_chats.update(resolved_excludes_in_cfg)
        self._logger.info(f"Final excluded chats for backend {self.id}: {self.excluded_chats or 'None'}")

        # åŠ è½½æœ€æ–°æ¶ˆæ¯ç¼“å­˜ (åœ¨å¤„ç†æ’é™¤åˆ—è¡¨å’ŒéªŒè¯ç›‘æ§åˆ—è¡¨ä¹‹å‰)
        self._load_newest_messages_on_startup()

        # å¯åŠ¨æ—¶æ£€æŸ¥ç›‘æ§çš„èŠå¤©æ˜¯å¦ä»ç„¶å¯è®¿é—®ï¼Œå¹¶ç§»é™¤æ— æ•ˆçš„æˆ–è¢«æ’é™¤çš„
        chats_to_remove = set()
        # è¿­ä»£ monitored_chats çš„å‰¯æœ¬è¿›è¡Œæ£€æŸ¥
        for chat_id in list(self.monitored_chats):
            try:
                # å¦‚æœå¯¹è¯åœ¨æœ€ç»ˆçš„æ’é™¤åˆ—è¡¨ä¸­ï¼Œå°†å…¶æ ‡è®°ä¸ºç§»é™¤
                if chat_id in self.excluded_chats:
                     self._logger.info(f"Chat {chat_id} is excluded, removing from monitoring.")
                     chats_to_remove.add(chat_id)
                     continue
                # å°è¯•è·å–å¯¹è¯åç§°ä»¥æ£€æŸ¥å¯è®¿é—®æ€§
                chat_name = await self.translate_chat_id(chat_id)
                self._logger.info(f'Monitoring active for "{chat_name}" ({chat_id})')
            except EntityNotFoundError:
                 # å¦‚æœæ‰¾ä¸åˆ°å®ä½“æˆ–æ— æƒè®¿é—®ï¼Œæ ‡è®°ä¸ºç§»é™¤
                 self._logger.warning(f'Monitored chat_id {chat_id} not found/accessible, removing from monitor list.')
                 chats_to_remove.add(chat_id)
            except Exception as e:
                # å¤„ç†æ£€æŸ¥è¿‡ç¨‹ä¸­çš„å…¶ä»–å¼‚å¸¸ï¼ŒåŒæ ·æ ‡è®°ä¸ºç§»é™¤
                self._logger.error(f'Exception checking monitored chat {chat_id}: {e}, removing from monitor list.')
                chats_to_remove.add(chat_id)

        # æ‰§è¡Œç§»é™¤æ“ä½œ
        if chats_to_remove:
            for chat_id in chats_to_remove:
                self.monitored_chats.discard(chat_id) # ä»ç›‘æ§é›†åˆä¸­ç§»é™¤
                self.newest_msg.pop(chat_id, None) # ä»æœ€æ–°æ¶ˆæ¯ç¼“å­˜ä¸­ç§»é™¤
            self._logger.info(f'Removed {len(chats_to_remove)} chats from active monitoring.')

        # æ³¨å†Œ Telethon äº‹ä»¶é’©å­ä»¥æ¥æ”¶å®æ—¶æ¶ˆæ¯
        self._register_hooks()
        self._logger.info(f"Backend bot {self.id} started successfully.")


    def search(self, q: str, in_chats: Optional[List[int]], page_len: int, page_num: int, file_filter: str = "all") -> SearchResult:
        """å°†æœç´¢è¯·æ±‚è½¬å‘ç»™ Indexer"""
        # è®°å½•æœç´¢è¯·æ±‚çš„åŸºæœ¬ä¿¡æ¯
        self._logger.debug(f"Backend {self.id} search: q='{brief_content(q)}', chats={in_chats}, page={page_num}, filter={file_filter}")
        try:
            # è°ƒç”¨ Indexer çš„ search æ–¹æ³•æ‰§è¡Œæœç´¢
            result = self._indexer.search(q, in_chats, page_len, page_num, file_filter=file_filter)
            # è®°å½•æœç´¢ç»“æœçš„åŸºæœ¬ä¿¡æ¯
            self._logger.debug(f"Search returned {result.total_results} total hits, {len(result.hits)} on page {page_num}.")
            return result
        except Exception as e:
             # è®°å½•åç«¯æœç´¢æ‰§è¡Œå¤±è´¥çš„é”™è¯¯
             self._logger.error(f"Backend search execution failed for {self.id}: {e}", exc_info=True)
             # è¿”å›ä¸€ä¸ªç©ºçš„ SearchResult å¯¹è±¡ï¼Œè¡¨ç¤ºæœç´¢å¤±è´¥
             return SearchResult([], True, 0)


    def rand_msg(self) -> IndexMsg:
        """ä» Indexer è·å–éšæœºæ¶ˆæ¯"""
        try:
            # è°ƒç”¨ Indexer çš„æ–¹æ³•æ¥æ£€ç´¢éšæœºæ–‡æ¡£
            return self._indexer.retrieve_random_document()
        except IndexError:
            # å¦‚æœç´¢å¼•ä¸ºç©ºï¼Œåˆ™æŠ›å‡ºç‰¹å®šçš„ IndexError
            self._logger.warning("Cannot retrieve random message: Index is empty.")
            raise IndexError("Index is empty, cannot retrieve random message.")
        except Exception as e:
            # è®°å½•æ£€ç´¢éšæœºæ–‡æ¡£æ—¶å‘ç”Ÿçš„å…¶ä»–é”™è¯¯
            self._logger.error(f"Error retrieving random document: {e}", exc_info=True)
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†
            raise


    def is_empty(self, chat_id: Optional[int] = None) -> bool:
        """æ£€æŸ¥ç´¢å¼•æˆ–ç‰¹å®šå¯¹è¯æ˜¯å¦ä¸ºç©º"""
        try:
            # è°ƒç”¨ Indexer çš„ is_empty æ–¹æ³•
            return self._indexer.is_empty(chat_id)
        except Exception as e:
            # è®°å½•æ£€æŸ¥ç´¢å¼•æ˜¯å¦ä¸ºç©ºæ—¶å‘ç”Ÿçš„é”™è¯¯
            self._logger.error(f"Error checking index emptiness for {chat_id}: {e}")
            # åœ¨å‡ºé”™çš„æƒ…å†µä¸‹ï¼Œä¿å®ˆåœ°è¿”å› Trueï¼ˆè®¤ä¸ºç´¢å¼•ä¸ºç©ºï¼‰
            return True


    # *************************************************************************
    # * FUNCTION MODIFIED BELOW                                               *
    # *************************************************************************
    async def download_history(self, chat_id: int, min_id: int, max_id: int, call_back: Optional[callable] = None):
        """
        ä¸‹è½½æŒ‡å®šå¯¹è¯çš„å†å²è®°å½•å¹¶æ·»åŠ åˆ°ç´¢å¼•ã€‚

        :param chat_id: åŸå§‹å¯¹è¯ ID (å°†è¢«è½¬æ¢ä¸º share_id)ã€‚
        :param min_id: è¦ä¸‹è½½çš„æœ€å°æ¶ˆæ¯ ID (ä¸åŒ…æ‹¬)ã€‚
        :param max_id: è¦ä¸‹è½½çš„æœ€å¤§æ¶ˆæ¯ ID (0 è¡¨ç¤ºæ— ä¸Šé™ï¼Œä¼šè·å–æ¯” min_id æ›´æ–°çš„æ‰€æœ‰æ¶ˆæ¯)ã€‚
        :param call_back: å¯é€‰çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºæŠ¥å‘Šè¿›åº¦ (æ¥æ”¶ cur_id, dl_count)ã€‚
        """
        task_name = f"DownloadHistory-{chat_id}"
        self._logger.info(f"Starting task: {task_name} (min={min_id}, max={max_id})")
        share_id = -1 # åˆå§‹åŒ–ä¸ºæ— æ•ˆå€¼
        try:
            share_id = get_share_id(chat_id) # è½¬æ¢ä¸º share_id
        except Exception as e:
            self._logger.error(f"Invalid chat_id format for download: {chat_id}, error: {e}")
            raise EntityNotFoundError(f"æ— æ•ˆçš„å¯¹è¯ ID æ ¼å¼: {chat_id}") # æŠ›å‡ºç‰¹å®šçš„é”™è¯¯ç±»å‹

        task_name = f"DownloadHistory-{share_id}" # æ›´æ–°ä»»åŠ¡å
        self._logger.info(f'Downloading history for {share_id} (raw_id={chat_id}, min={min_id}, max={max_id})')
        # æ£€æŸ¥å¯¹è¯æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if share_id in self.excluded_chats:
            self._logger.warning(f"Skipping download for excluded chat {share_id}.")
            raise ValueError(f"å¯¹è¯ {share_id} å·²è¢«æ’é™¤ï¼Œæ— æ³•ä¸‹è½½ã€‚") # æŠ›å‡º ValueError è¡¨ç¤ºæ“ä½œä¸å…è®¸

        # --- ç›‘æ§åé¦ˆé€»è¾‘ ---
        is_newly_monitored = False
        if share_id not in self.monitored_chats:
            is_newly_monitored = True
            self.monitored_chats.add(share_id)
            # æ·»åŠ åˆ°ç›‘æ§åˆ—è¡¨çš„æ—¥å¿—åé¦ˆ
            self._logger.info(f"[Monitoring] Added chat {share_id} to monitored list during download request.")
            # **å»ºè®®**: å‰ç«¯åœ¨è°ƒç”¨æ­¤å‡½æ•°æˆåŠŸåï¼Œå¯ä»¥å‘ç”¨æˆ·å‘é€ä¸€æ¡æ˜ç¡®çš„ç¡®è®¤æ¶ˆæ¯ï¼Œä¾‹å¦‚:
            # await event.reply(f"âœ… å¯¹è¯ {chat_name} ({share_id}) å·²æˆåŠŸæ·»åŠ åˆ°ç›‘æ§åˆ—è¡¨ã€‚")

        msg_list: List[IndexMsg] = [] # å­˜å‚¨ä» Telegram è·å–å¹¶å‡†å¤‡ç´¢å¼•çš„æ¶ˆæ¯
        downloaded_count: int = 0 # å®é™…æ„é€ äº† IndexMsg çš„æ¶ˆæ¯æ•°é‡
        processed_count: int = 0 # Telethon `iter_messages` è¿”å›çš„æ€»é¡¹ç›®æ•°
        newest_msg_in_batch: Optional[IndexMsg] = None # è®°å½•æ­¤æ‰¹æ¬¡ä¸­æœ€æ–°çš„æ¶ˆæ¯
        indexed_count_in_batch: int = 0

        try:
            # ä½¿ç”¨ Telethon å¼‚æ­¥è¿­ä»£æŒ‡å®šå¯¹è¯çš„æ¶ˆæ¯å†å²
            async for tg_message in self.session.iter_messages(entity=share_id, min_id=min_id, max_id=max_id, limit=None, reverse=True): # reverse=True ç¡®ä¿ä»æ—§åˆ°æ–°å¤„ç†ï¼Œä¾¿äºç¡®å®š newest_msg
                processed_count += 1
                if not isinstance(tg_message, TgMessage): continue

                url = f'https://t.me/c/{share_id}/{tg_message.id}'
                sender = await self._get_sender_name(tg_message)
                post_time = tg_message.date
                if not isinstance(post_time, datetime):
                    self._logger.warning(f"Message {url} has invalid date type {type(post_time)}, using current time.")
                    post_time = datetime.now()

                msg_text, filename = '', None
                if tg_message.file and hasattr(tg_message.file, 'name') and tg_message.file.name:
                    filename = tg_message.file.name
                    if tg_message.text: msg_text = escape_content(tg_message.text.strip())
                elif tg_message.text:
                    msg_text = escape_content(tg_message.text.strip())

                if msg_text or filename:
                    try:
                        msg = IndexMsg(content=msg_text or "", url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                        msg_list.append(msg)
                        downloaded_count += 1
                        # æ›´æ–°æ­¤æ‰¹æ¬¡ä¸­é‡åˆ°çš„æœ€æ–°æ¶ˆæ¯
                        newest_msg_in_batch = msg
                    except Exception as create_e:
                        self._logger.error(f"Error creating IndexMsg for {url}: {create_e}")

                if call_back and processed_count % 100 == 0:
                     try: await call_back(tg_message.id, downloaded_count)
                     except Exception as cb_e: self._logger.warning(f"Error in download callback: {cb_e}")
                if processed_count % 500 == 0:
                    await asyncio.sleep(0.01) # é‡Šæ”¾äº‹ä»¶å¾ªç¯

            # --- å¤„ç†ä¸‹è½½é”™è¯¯ ---
            # ... (é”™è¯¯å¤„ç†éƒ¨åˆ†ä¿æŒä¸å˜) ...
        except telethon.errors.rpcerrorlist.ChannelPrivateError as e:
            self._logger.error(f"Permission denied for chat {share_id}. Is the backend account a member? Error: {e}")
            self.monitored_chats.discard(share_id) # ç§»é™¤æ— æ³•è®¿é—®çš„å¯¹è¯
            if is_newly_monitored: self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to access error.")
            raise EntityNotFoundError(f"æ— æ³•è®¿é—®å¯¹è¯ {chat_id} ({share_id})ï¼Œè¯·ç¡®ä¿åç«¯è´¦å·æ˜¯å…¶æˆå‘˜ã€‚") from e
        except (telethon.errors.rpcerrorlist.ChatIdInvalidError, telethon.errors.rpcerrorlist.PeerIdInvalidError):
            self._logger.error(f"Chat ID {share_id} (raw: {chat_id}) invalid or peer not found.")
            self.monitored_chats.discard(share_id)
            if is_newly_monitored: self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to invalid ID.")
            raise EntityNotFoundError(f"æ— æ•ˆå¯¹è¯ ID æˆ–æ— æ³•æ‰¾åˆ° Peer: {chat_id} ({share_id})")
        except ValueError as e:
             if "Cannot find any entity corresponding to" in str(e) or "Could not find the input entity for" in str(e):
                 self._logger.error(f"Cannot find entity for chat {share_id} (raw: {chat_id}). Error: {e}")
                 self.monitored_chats.discard(share_id)
                 if is_newly_monitored: self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to entity not found.")
                 raise EntityNotFoundError(f"æ— æ³•æ‰¾åˆ°å¯¹è¯å®ä½“: {chat_id} ({share_id})") from e
             else:
                 self._logger.error(f"ValueError iterating messages for {share_id}: {e}", exc_info=True)
                 raise # é‡æ–°æŠ›å‡º
        except Exception as e:
            self._logger.error(f"Error iterating messages for {share_id}: {e}", exc_info=True)
            # å¦‚æœåœ¨ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œä¹Ÿè€ƒè™‘ç§»é™¤ï¼ˆå¦‚æœåˆšæ·»åŠ çš„è¯ï¼‰
            if is_newly_monitored:
                self.monitored_chats.discard(share_id)
                self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to download error.")
            raise RuntimeError(f"ä¸‹è½½å¯¹è¯ {share_id} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯")

        # --- æ‰¹é‡å†™å…¥ç´¢å¼• ---
        self._logger.info(f'History fetch complete for {share_id}: {downloaded_count} messages to index out of {processed_count} processed.')
        if not msg_list:
            self._logger.info(f"No indexable messages found for chat {share_id} in the specified range.")
            # å¦‚æœæ˜¯æ–°ç›‘æ§çš„ä½†æ²¡ä¸‹è½½åˆ°æ¶ˆæ¯ï¼Œä»ç„¶ä¿ç•™åœ¨ç›‘æ§åˆ—è¡¨
            return

        writer: Optional[IndexWriter] = None
        try:
            writer = self._indexer.ix.writer()
            for i, msg in enumerate(msg_list):
                try:
                    self._indexer.add_document(msg, writer)
                    indexed_count_in_batch += 1
                    if i > 0 and i % 1000 == 0:
                        self._logger.debug(f"Batch write progress for {share_id}: {i} messages added...")
                        await asyncio.sleep(0.01)
                except Exception as add_e:
                    self._logger.error(f"Error adding document {msg.url} to batch writer: {add_e}")
            writer.commit()
            self._logger.info(f'Write index commit ok for {indexed_count_in_batch} messages from chat {share_id}')
            # æ›´æ–°è¯¥å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯ç¼“å­˜
            if newest_msg_in_batch:
                 current_chat_id = int(newest_msg_in_batch.chat_id)
                 if current_chat_id not in self.newest_msg or newest_msg_in_batch.post_time > self.newest_msg[current_chat_id].post_time:
                      self.newest_msg[current_chat_id] = newest_msg_in_batch
                      self._logger.debug(f"Updated newest msg cache for {current_chat_id} to {newest_msg_in_batch.url}")
        except writing.LockError:
            self._logger.error("Index is locked during batch write. Downloaded messages are lost.")
            if writer and not writer.is_closed:
                try: writer.cancel()
                except Exception as cancel_e: self._logger.error(f"Error cancelling writer after lock: {cancel_e}")
            # å¦‚æœæ˜¯å› ä¸ºé”é”™è¯¯å¯¼è‡´å†™å…¥å¤±è´¥ï¼Œå¹¶ä¸”æ˜¯åˆšæ·»åŠ çš„ç›‘æ§ï¼Œåˆ™ç§»é™¤
            if is_newly_monitored:
                 self.monitored_chats.discard(share_id)
                 self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to index lock during initial write.")
            raise RuntimeError("Index is locked, cannot write downloaded messages.")
        except Exception as e:
            self._logger.error(f"Error writing batch index for {share_id}: {e}", exc_info=True)
            if writer and not writer.is_closed:
                try: writer.cancel()
                except Exception as cancel_e: self._logger.error(f"Error cancelling writer after general error: {cancel_e}")
            # å¦‚æœæ˜¯å› ä¸ºå†™å…¥é”™è¯¯å¯¼è‡´å†™å…¥å¤±è´¥ï¼Œå¹¶ä¸”æ˜¯åˆšæ·»åŠ çš„ç›‘æ§ï¼Œåˆ™ç§»é™¤
            if is_newly_monitored:
                 self.monitored_chats.discard(share_id)
                 self._logger.info(f"[Monitoring] Removed newly added chat {share_id} due to index write error during initial write.")
            raise RuntimeError(f"å†™å…¥ç´¢å¼•æ—¶å‡ºé”™ for {share_id}")
        finally:
             self._logger.info(f"Finished task: {task_name}")

    def clear(self, chat_ids: Optional[List[int]] = None):
        """
        æ¸…é™¤ç´¢å¼•æ•°æ®ã€‚

        :param chat_ids: å¯é€‰ï¼Œè¦æ¸…é™¤çš„ chat_id åˆ—è¡¨ (åŸå§‹IDæˆ–share_idçš†å¯)ã€‚å¦‚æœä¸º Noneï¼Œåˆ™æ¸…é™¤æ‰€æœ‰ç´¢å¼•ã€‚
        """
        if chat_ids is not None:
            # æ¸…é™¤æŒ‡å®šå¯¹è¯çš„æ•°æ®
            share_ids_to_clear = set()
            invalid_inputs = []
            for cid in chat_ids:
                try:
                    # å°è¯•ç›´æ¥ä½œä¸ºintæˆ–strè·å–share_id
                    share_ids_to_clear.add(get_share_id(cid))
                except Exception:
                    invalid_inputs.append(str(cid))

            if invalid_inputs:
                self._logger.warning(f"Invalid chat IDs provided for clearing: {', '.join(invalid_inputs)}")
            if not share_ids_to_clear:
                self._logger.warning("No valid share IDs to clear.")
                return # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ IDï¼Œåˆ™ä¸æ‰§è¡Œä»»ä½•æ“ä½œ

            self._logger.info(f"Attempting to clear index data for chats: {share_ids_to_clear}")
            try:
                # ä½¿ç”¨ Whoosh writer æŒ‰ 'chat_id' å­—æ®µåˆ é™¤æ–‡æ¡£
                with self._indexer.ix.writer() as w:
                    total_deleted = 0
                    for share_id in share_ids_to_clear:
                        deleted_count = w.delete_by_term('chat_id', str(share_id))
                        total_deleted += deleted_count
                        # ä»ç›‘æ§åˆ—è¡¨å’Œæœ€æ–°æ¶ˆæ¯ç¼“å­˜ä¸­ç§»é™¤
                        if self.monitored_chats.discard(share_id): # discard ä¸ä¼šæŠ›é”™
                           self._logger.info(f'[Monitoring] Chat {share_id} removed from monitoring due to /clear command.')
                        if self.newest_msg.pop(share_id, None):
                           self._logger.debug(f'Removed newest msg cache for cleared chat {share_id}')
                        self._logger.info(f'Cleared {deleted_count} docs for chat {share_id}')
                    self._logger.info(f"Total {total_deleted} documents deleted for specified chats.")
            except writing.LockError:
                self._logger.error(f"Index locked. Failed to clear index for chats {share_ids_to_clear}.")
            except Exception as e:
                self._logger.error(f"Error clearing index for chats {share_ids_to_clear}: {e}", exc_info=True)
        else:
            # æ¸…é™¤æ‰€æœ‰ç´¢å¼•æ•°æ®
            self._logger.warning('Attempting to clear ALL index data.')
            try:
                # è°ƒç”¨ Indexer çš„ clear æ–¹æ³•
                self._indexer.clear()
                # æ¸…ç©ºç›‘æ§åˆ—è¡¨å’Œæœ€æ–°æ¶ˆæ¯ç¼“å­˜
                if self.monitored_chats:
                    self._logger.info(f"[Monitoring] Removing all {len(self.monitored_chats)} chats from monitoring due to /clear all.")
                    self.monitored_chats.clear()
                if self.newest_msg:
                    self._logger.debug(f"Clearing newest message cache for {len(self.newest_msg)} chats.")
                    self.newest_msg.clear()
                self._logger.info('Cleared all index data and stopped monitoring all chats.')
            except writing.LockError:
                self._logger.error("Index locked. Failed to clear all index data.")
            except Exception as e:
                self._logger.error(f"Error clearing all index data: {e}", exc_info=True)


    async def find_chat_id(self, q: str) -> List[int]:
        """ä½¿ç”¨ä¼šè¯æŸ¥æ‰¾åŒ¹é…å…³é”®è¯çš„å¯¹è¯ ID (è¿”å› share_id åˆ—è¡¨)"""
        try:
            # è°ƒç”¨ session çš„æ–¹æ³•æŸ¥æ‰¾å¯¹è¯ ID
            return await self.session.find_chat_id(q)
        except Exception as e:
            # è®°å½•æŸ¥æ‰¾å¯¹è¯ ID æ—¶çš„é”™è¯¯
            self._logger.error(f"Error finding chat id for '{q}': {e}")
            return [] # è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºæŸ¥æ‰¾å¤±è´¥

    async def get_index_status(self, length_limit: int = 4000) -> str:
        """è·å–åç«¯ç´¢å¼•çŠ¶æ€çš„æ–‡æœ¬æè¿° (ä¿®æ­£è®¡æ•°å’Œé”™è¯¯å¤„ç†é€»è¾‘, å¢åŠ æ—¥å¿—)"""
        cur_len = 0
        sb = [] # ä½¿ç”¨åˆ—è¡¨å­˜å‚¨å­—ç¬¦ä¸²ç‰‡æ®µï¼Œæœ€å join
        searcher = None # åˆå§‹åŒ– searcher å˜é‡

        # 1. è·å–æ€»æ–‡æ¡£æ•°
        total_docs = -1 # æ ‡è®°è·å–å¤±è´¥
        try:
            self._logger.debug("Attempting to get total document count from index...")
            total_docs = self._indexer.ix.doc_count()
            self._logger.debug(f"Successfully retrieved total document count: {total_docs}")
        except Exception as e:
            self._logger.error(f"Failed get total doc count: {e}", exc_info=True) # Log with traceback
        # æ·»åŠ å¤´éƒ¨ä¿¡æ¯ (åç«¯ ID, ä¼šè¯å, æ€»æ¶ˆæ¯æ•°)
        sb.append(f'åç«¯ "{self.id}" (ä¼šè¯: "{self.session.name}") æ€»æ¶ˆæ¯: <b>{total_docs if total_docs >= 0 else "[è·å–å¤±è´¥]"}</b>\n\n')

        # å®šä¹‰è¶…å‡ºé•¿åº¦é™åˆ¶æ—¶çš„æç¤ºä¿¡æ¯
        overflow_msg = f'\n\n(éƒ¨åˆ†ä¿¡æ¯å› é•¿åº¦é™åˆ¶æœªæ˜¾ç¤º)'

        # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥æ·»åŠ æ–°å†…å®¹æ˜¯å¦ä¼šè¶…å‡ºé•¿åº¦é™åˆ¶
        def append_msg(msg_list: List[str]) -> bool:
            nonlocal cur_len
            new_len = sum(len(msg) for msg in msg_list)
            if cur_len + new_len > length_limit - len(overflow_msg) - 50:
                return True # è¿”å› True è¡¨ç¤ºè¶…å‡ºé™åˆ¶
            cur_len += new_len
            sb.extend(msg_list)
            return False # è¿”å› False è¡¨ç¤ºæœªè¶…å‡ºé™åˆ¶

        # 2. æ˜¾ç¤ºæ’é™¤åˆ—è¡¨
        if self.excluded_chats:
            excluded_list = sorted(list(self.excluded_chats))
            if append_msg([f'{len(excluded_list)} ä¸ªå¯¹è¯è¢«ç¦æ­¢ç´¢å¼•:\n']):
                sb.append(overflow_msg); return ''.join(sb)
            for chat_id in excluded_list:
                try: chat_html = await self.format_dialog_html(chat_id)
                except Exception: chat_html = f"å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)"
                if append_msg([f'- {chat_html}\n']):
                    sb.append(overflow_msg); return ''.join(sb)
            if sb and sb[-1] != '\n\n': sb.append('\n')

        # 3. æ˜¾ç¤ºç›‘æ§åˆ—è¡¨å’Œè®¡æ•°
        monitored_chats_list = sorted(list(self.monitored_chats))
        if append_msg([f'æ€»è®¡ {len(monitored_chats_list)} ä¸ªå¯¹è¯è¢«åŠ å…¥äº†ç´¢å¼•:\n']):
            sb.append(overflow_msg); return ''.join(sb)

        # 4. è·å–æ¯ä¸ªç›‘æ§å¯¹è¯çš„è¯¦ç»†ä¿¡æ¯
        detailed_status_error = None
        self._logger.debug(f"Getting status for {len(monitored_chats_list)} monitored chats.")
        try:
             self._logger.debug("Attempting to open index searcher for chat counts...")
             searcher = self._indexer.ix.searcher() # åœ¨å¾ªç¯å¤–æ‰“å¼€ searcher
             self._logger.debug("Index searcher opened successfully.")
             for chat_id in monitored_chats_list:
                 msg_for_chat = []
                 num = -1 # åˆå§‹åŒ–è®¡æ•°ä¸ºé”™è¯¯çŠ¶æ€ (-1)
                 chat_id_str = str(chat_id)

                 # å°è¯•è·å–è¯¥å¯¹è¯çš„æ–‡æ¡£è®¡æ•°
                 try:
                     query = Term('chat_id', chat_id_str)
                     self._logger.debug(f"Counting documents for chat {chat_id_str} with query: {query}")
                     num = searcher.doc_count(query=query)
                     self._logger.debug(f"Count for chat {chat_id_str}: {num}")
                 except searching.SearchError as search_e:
                     self._logger.error(f"Whoosh SearchError counting docs for chat {chat_id_str}: {search_e}", exc_info=True)
                     if not detailed_status_error: detailed_status_error = "éƒ¨åˆ†å¯¹è¯è®¡æ•°å¤±è´¥ (SearchError)"
                 except Exception as e:
                     self._logger.error(f"Unexpected error counting docs for chat {chat_id_str}: {e}", exc_info=True)
                     if not detailed_status_error: detailed_status_error = "éƒ¨åˆ†å¯¹è¯è®¡æ•°å¤±è´¥ (æœªçŸ¥é”™è¯¯)"

                 # å°è¯•è·å–å¯¹è¯åç§°
                 try:
                     chat_html = await self.format_dialog_html(chat_id)
                 except Exception as name_e:
                     self._logger.error(f"Error getting name for chat {chat_id}: {name_e}")
                     chat_html = f"å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)"

                 # ç»„åˆå¯¹è¯ä¿¡æ¯å’Œè®¡æ•°ç»“æœ
                 count_str = "[è®¡æ•°å¤±è´¥]" if num < 0 else str(num)
                 msg_for_chat.append(f'- {chat_html} å…± {count_str} æ¡æ¶ˆæ¯\n')

                 # æ·»åŠ è¯¥å¯¹è¯çš„æœ€æ–°æ¶ˆæ¯ä¿¡æ¯
                 if newest_msg := self.newest_msg.get(chat_id):
                     display_parts = []
                     if newest_msg.filename: display_parts.append(f"ğŸ“ {newest_msg.filename}")
                     if newest_msg.content: display_parts.append(brief_content(newest_msg.content))
                     display = " ".join(display_parts) if display_parts else "(ç©ºæ¶ˆæ¯)"
                     esc_display = html.escape(display)
                     time_str = newest_msg.post_time.strftime("%y-%m-%d %H:%M") if isinstance(newest_msg.post_time, datetime) else "[æœªçŸ¥æ—¶é—´]"
                     msg_for_chat.append(f'  æœ€æ–°: <a href="{html.escape(newest_msg.url)}">{esc_display}</a> (@{time_str})\n')

                 # æ£€æŸ¥é•¿åº¦å¹¶å°è¯•æ·»åŠ 
                 if append_msg(msg_for_chat):
                     sb.append(overflow_msg); break # è¶…å‡ºåˆ™è·³å‡ºå¾ªç¯

             if detailed_status_error and not (sb and sb[-1].endswith(overflow_msg)):
                 if append_msg([f"\nè­¦å‘Š: {detailed_status_error}\n"]):
                     sb.append(overflow_msg)

        except writing.LockError:
             self._logger.error(f"Index locked, failed to open searcher for status.")
             if append_msg(["\né”™è¯¯ï¼šç´¢å¼•è¢«é”å®šï¼Œæ— æ³•è·å–è¯¦ç»†å¯¹è¯çŠ¶æ€ã€‚\n"]):
                 sb.append(overflow_msg)
        except Exception as e:
             self._logger.error(f"Failed to get detailed status (outside chat loop): {e}", exc_info=True)
             if append_msg(["\né”™è¯¯ï¼šæ— æ³•è·å–è¯¦ç»†çŠ¶æ€ã€‚\n"]):
                 sb.append(overflow_msg)
        finally:
            # ç¡®ä¿ searcher å¯¹è±¡åœ¨ä½¿ç”¨åè¢«å…³é—­
            if searcher:
                searcher.close()
                self._logger.debug("Searcher closed after getting index status.")
        # --- ç»“æŸè¯¦ç»†ä¿¡æ¯è·å– ---

        return ''.join(sb)

    async def translate_chat_id(self, chat_id: int) -> str:
        """ä½¿ç”¨ä¼šè¯å°† Chat ID (share_id) ç¿»è¯‘ä¸ºåç§°"""
        try:
            return await self.session.translate_chat_id(int(chat_id))
        except (telethon.errors.rpcerrorlist.ChannelPrivateError, telethon.errors.rpcerrorlist.ChatIdInvalidError, ValueError, TypeError) as e:
            self._logger.warning(f"Could not translate chat_id {chat_id}: {type(e).__name__}")
            raise EntityNotFoundError(f"æ— æ³•è®¿é—®æˆ–æ— æ•ˆ Chat ID: {chat_id}")
        except EntityNotFoundError:
            self._logger.warning(f"Entity not found for {chat_id} during translation.")
            raise
        except Exception as e:
            self._logger.error(f"Error translating chat_id {chat_id}: {e}")
            raise EntityNotFoundError(f"è·å–å¯¹è¯ {chat_id} åç§°æ—¶å‡ºé”™") from e


    async def str_to_chat_id(self, chat: str) -> int:
        """å°†å­—ç¬¦ä¸²ï¼ˆç”¨æˆ·åã€é“¾æ¥æˆ– IDï¼‰è½¬æ¢ä¸º share_id"""
        try:
            return get_share_id(int(chat))
        except ValueError:
            try:
                return get_share_id(await self.session.str_to_chat_id(chat))
            except EntityNotFoundError:
                self._logger.warning(f"Entity not found for '{chat}' using session.")
                raise
            except Exception as e_inner:
                self._logger.error(f"Error converting '{chat}' to chat_id via session: {e_inner}")
                raise EntityNotFoundError(f"è§£æ '{chat}' æ—¶å‡ºé”™") from e_inner
        except Exception as e_outer:
            self._logger.error(f"Error converting '{chat}' to chat_id directly: {e_outer}")
            raise EntityNotFoundError(f"è§£æ '{chat}' æ—¶å‡ºé”™") from e_outer


    async def format_dialog_html(self, chat_id: int) -> str:
        """æ ¼å¼åŒ–å¯¹è¯çš„ HTML é“¾æ¥å’Œåç§°ï¼ŒåŒ…å« share_id"""
        try:
            name = await self.translate_chat_id(int(chat_id))
            esc_name = html.escape(name)
            # åˆ›å»ºæŒ‡å‘å¯¹è¯ç¬¬ä¸€æ¡æ¶ˆæ¯çš„é“¾æ¥ (é€šå¸¸ç”¨äºè·³è½¬åˆ°å¯¹è¯)
            return f'<a href="https://t.me/c/{chat_id}/1">{esc_name}</a> (`{chat_id}`)'
        except EntityNotFoundError: return f'æœªçŸ¥å¯¹è¯ (`{chat_id}`)'
        except ValueError: return f'æ— æ•ˆå¯¹è¯ ID (`{chat_id}`)'
        except Exception as e:
            self._logger.warning(f"Error formatting html for {chat_id}: {e}")
            return f'å¯¹è¯ `{chat_id}` (è·å–åç§°å‡ºé”™)'


    def _should_monitor(self, chat_id: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç›‘æ§æ­¤å¯¹è¯çš„æ¶ˆæ¯ (åŸºäºé…ç½®å’Œç›‘æ§åˆ—è¡¨)"""
        try:
            share_id = get_share_id(chat_id)
            if share_id in self.excluded_chats: return False
            # å¦‚æœé…ç½®äº† monitor_all=Trueï¼Œæˆ–è€…è¯¥å¯¹è¯åœ¨å½“å‰çš„ç›‘æ§åˆ—è¡¨ä¸­ï¼Œåˆ™ç›‘æ§
            should = self._cfg.monitor_all or (share_id in self.monitored_chats)
            # self._logger.debug(f"Should monitor {share_id}? monitor_all={self._cfg.monitor_all}, in_list={share_id in self.monitored_chats} -> {should}")
            return should
        except Exception as e:
            self._logger.warning(f"Error determining monitor status for chat {chat_id}: {e}")
            return False


    @staticmethod
    async def _get_sender_name(message: TgMessage) -> str:
        """è·å–æ¶ˆæ¯å‘é€è€…çš„åç§°ï¼ˆç”¨æˆ·æˆ–é¢‘é“/ç¾¤ç»„æ ‡é¢˜ï¼‰"""
        sender_name = ''
        try:
            sender = await message.get_sender()
            if isinstance(sender, User):
                sender_name = format_entity_name(sender)
            elif hasattr(sender, 'title'): # Channels, Chats
                sender_name = sender.title
            elif hasattr(sender, 'username'): # Fallback for users without full name?
                sender_name = f"@{sender.username}"
        except Exception as e:
            logger.debug(f"Could not get sender name for message {getattr(message, 'id', 'N/A')}: {e}")
        return sender_name or '' # Ensure non-None return

    def _register_hooks(self):
        """æ³¨å†Œ Telethon äº‹ä»¶é’©å­ï¼Œç”¨äºå®æ—¶æ¥æ”¶å’Œå¤„ç†æ¶ˆæ¯"""
        self._logger.info("Registering Telethon event handlers...")
        # ç”¨äºè·Ÿè¸ªå“ªäº› chat_id å·²ç»è¢«è®°å½•ä¸ºâ€œé¦–æ¬¡ç›‘æ§åˆ°â€
        _first_monitor_logged: Set[int] = set()

        # --- å¤„ç†æ–°æ¶ˆæ¯ ---
        @self.session.on(events.NewMessage())
        async def client_message_handler(event: events.NewMessage.Event):
            # åŸºç¡€æ£€æŸ¥ï¼šç¡®ä¿æœ‰ chat_id
            if not hasattr(event, 'chat_id') or event.chat_id is None:
                self._logger.debug("Ignoring event with no chat_id.")
                return

            try:
                share_id = get_share_id(event.chat_id)
                # --- ç›‘æ§æ£€æŸ¥å’Œåé¦ˆ ---
                if not self._should_monitor(share_id):
                    # self._logger.debug(f"Ignoring message from non-monitored chat {share_id}.")
                    return # ä¸å¤„ç†ä¸ç›‘æ§çš„å¯¹è¯

                # å¦‚æœæ˜¯é¦–æ¬¡å¤„ç†è¿™ä¸ªç›‘æ§å¯¹è¯çš„æ¶ˆæ¯ï¼ˆä¸”æœªåœ¨æ—¥å¿—ä¸­è®°å½•è¿‡ï¼‰ï¼Œæ·»åŠ æ—¥å¿—
                if share_id not in _first_monitor_logged:
                     # æ£€æŸ¥å®ƒæ˜¯å¦ç¡®å®åœ¨ç›‘æ§åˆ—è¡¨æˆ– monitor_all=True
                     if share_id in self.monitored_chats or self._cfg.monitor_all:
                         self._logger.info(f"[Monitoring] First message processed from monitored chat {share_id}.")
                         _first_monitor_logged.add(share_id)
                     # else: ç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼Œå› ä¸º _should_monitor å·²æ£€æŸ¥

                # --- æ¶ˆæ¯å¤„ç†é€»è¾‘ (ä¿æŒä¸å˜) ---
                url = f'https://t.me/c/{share_id}/{event.id}'
                sender = await self._get_sender_name(event.message)
                post_time = event.message.date
                if not isinstance(post_time, datetime):
                    self._logger.warning(f"New message {url} has invalid date type {type(post_time)}, using current time.")
                    post_time = datetime.now()

                msg_text, filename = '', None
                if event.message.file and hasattr(event.message.file, 'name') and event.message.file.name:
                    filename = event.message.file.name
                    if event.message.text: msg_text = escape_content(event.message.text.strip())
                    self._logger.info(f'New file {url} from "{sender}" in chat {share_id}: "{filename}" Caption:"{brief_content(msg_text)}"')
                elif event.message.text:
                    msg_text = escape_content(event.message.text.strip())
                    if not msg_text: self._logger.debug(f"Ignoring empty/whitespace message {url} in {share_id}."); return
                    self._logger.info(f'New msg {url} from "{sender}" in chat {share_id}: "{brief_content(msg_text)}"')
                else:
                    self._logger.debug(f"Ignoring message {url} with no text or file in {share_id}.")
                    return

                msg = IndexMsg(content=msg_text or "", url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                if share_id not in self.newest_msg or msg.post_time >= self.newest_msg[share_id].post_time:
                    self.newest_msg[share_id] = msg
                    self._logger.debug(f"Updated newest cache for {share_id} to {url}")
                try:
                    self._indexer.add_document(msg)
                except Exception as e:
                    self._logger.error(f"Error adding doc {url} to index: {e}", exc_info=True)
            except Exception as e:
                chat_id_repr = getattr(event, 'chat_id', 'N/A')
                self._logger.error(f"Error processing new message in chat {chat_id_repr}: {e}", exc_info=True)

        # --- å¤„ç†æ¶ˆæ¯ç¼–è¾‘ ---
        @self.session.on(events.MessageEdited())
        async def client_message_update_handler(event: events.MessageEdited.Event):
            if not hasattr(event, 'chat_id') or event.chat_id is None: return
            try:
                share_id = get_share_id(event.chat_id)
                if not self._should_monitor(share_id): return

                # ç¼–è¾‘å¤„ç†é€»è¾‘ (ä¿æŒä¸å˜)
                # ...
                url = f'https://t.me/c/{share_id}/{event.id}'
                new_msg_text = escape_content(event.message.text.strip()) if event.message.text else ''
                self._logger.info(f'Msg {url} edited in chat {share_id}. Checking for update...')

                try:
                    old_fields = self._indexer.get_document_fields(url=url)
                    if old_fields:
                        if old_fields.get('content') == new_msg_text:
                            self._logger.debug(f"Edit event {url} has same content, skipping index update.")
                            return
                        new_fields = old_fields.copy(); new_fields['content'] = new_msg_text
                        new_fields.setdefault('chat_id', str(share_id))
                        old_time = old_fields.get('post_time')
                        new_fields['post_time'] = old_time if isinstance(old_time, datetime) else (event.message.date or datetime.now())
                        if not isinstance(new_fields['post_time'], datetime): new_fields['post_time'] = datetime.now()
                        new_fields.setdefault('sender', old_fields.get('sender', await self._get_sender_name(event.message) or ''))
                        new_fields.setdefault('filename', old_fields.get('filename', None))
                        new_fields.setdefault('url', url)
                        new_fields['has_file'] = 1 if new_fields.get('filename') else 0

                        self._indexer.replace_document(url=url, new_fields=new_fields)
                        self._logger.info(f'Updated msg content in index for {url}')

                        if share_id in self.newest_msg and self.newest_msg[share_id].url == url:
                             try:
                                 # ä½¿ç”¨ Whoosh å­˜å‚¨çš„å­—æ®µç±»å‹é‡å»º IndexMsg
                                 # æ³¨æ„ï¼š Whoosh å­˜ chat_id ä¸º str, post_time ä¸º datetime, has_file ä¸º int
                                 rebuilt_msg = IndexMsg(
                                     content=new_fields['content'], url=new_fields['url'],
                                     chat_id=int(new_fields['chat_id']), # è½¬å› int
                                     post_time=new_fields['post_time'], # å·²ç»æ˜¯ datetime
                                     sender=new_fields['sender'], filename=new_fields['filename']
                                 )
                                 self.newest_msg[share_id] = rebuilt_msg
                                 self._logger.debug(f"Updated newest cache content for {url}")
                             except (ValueError, KeyError, TypeError) as cache_e:
                                 self._logger.error(f"Error reconstructing IndexMsg for cache update {url}: {cache_e}. Fields: {new_fields}")
                    else:
                         self._logger.warning(f'Edited msg {url} not found in index. Adding as new message.')
                         sender = await self._get_sender_name(event.message)
                         post_time = event.message.date or datetime.now()
                         if not isinstance(post_time, datetime): post_time = datetime.now()
                         filename = None # å‡è®¾ç¼–è¾‘ä¸æ”¹å˜æ–‡ä»¶ä¿¡æ¯
                         if new_msg_text:
                             msg = IndexMsg(content=new_msg_text, url=url, chat_id=share_id, post_time=post_time, sender=sender or "", filename=filename)
                             self._indexer.add_document(msg)
                             if share_id not in self.newest_msg or msg.post_time >= self.newest_msg[share_id].post_time:
                                 self.newest_msg[share_id] = msg
                                 self._logger.debug(f"Added edited msg {url} as newest cache for {share_id}")
                         else:
                             self._logger.debug(f"Ignoring edited message {url} with empty content and not found in index.")
                except Exception as e:
                    self._logger.error(f'Error updating/adding edited msg {url} in index: {e}', exc_info=True)
            except Exception as e:
                chat_id_repr = getattr(event, 'chat_id', 'N/A')
                self._logger.error(f"Error processing edited message in chat {chat_id_repr}: {e}", exc_info=True)

        # --- å¤„ç†æ¶ˆæ¯åˆ é™¤ ---
        @self.session.on(events.MessageDeleted())
        async def client_message_delete_handler(event: events.MessageDeleted.Event):
            if not hasattr(event, 'chat_id') or event.chat_id is None:
                self._logger.debug(f"Ignoring deletion event with no chat_id. Deleted IDs: {event.deleted_ids}")
                return
            try:
                share_id = get_share_id(event.chat_id)
                if not self._should_monitor(share_id):
                    self._logger.debug(f"Ignoring deletion event from non-monitored chat {share_id}. Deleted IDs: {event.deleted_ids}")
                    return

                # åˆ é™¤å¤„ç†é€»è¾‘ (ä¿æŒä¸å˜)
                # ...
                deleted_count_in_batch = 0
                urls_to_delete = [f'https://t.me/c/{share_id}/{mid}' for mid in event.deleted_ids]
                self._logger.info(f"Processing deletion of {len(urls_to_delete)} message(s) in chat {share_id}: {event.deleted_ids}")

                try:
                     with self._indexer.ix.writer() as writer:
                          for url in urls_to_delete:
                               if share_id in self.newest_msg and self.newest_msg[share_id].url == url:
                                    del self.newest_msg[share_id]
                                    self._logger.info(f"Removed newest cache for {share_id} due to deletion of {url}.")
                               try:
                                    count = writer.delete_by_term('url', url)
                                    if count > 0:
                                        deleted_count_in_batch += count
                                        self._logger.info(f"Deleted msg {url} from index.")
                                    else:
                                        self._logger.debug(f"Message {url} requested for deletion not found in index.")
                               except Exception as del_e:
                                    self._logger.error(f"Error deleting doc {url} from index: {del_e}")
                     if deleted_count_in_batch > 0:
                         self._logger.info(f'Finished deleting {deleted_count_in_batch} msgs from index for chat {share_id}')
                     else:
                         self._logger.info(f"No matching messages found in index to delete for chat {share_id} batch.")
                except writing.LockError:
                    self._logger.error(f"Index locked. Could not process deletions batch for {share_id}: {urls_to_delete}")
                except Exception as e:
                    self._logger.error(f"Error processing deletions batch for {share_id}: {e}", exc_info=True)
            except Exception as e:
                chat_id_repr = getattr(event, 'chat_id', 'N/A')
                self._logger.error(f"Error processing deleted event in chat {chat_id_repr}: {e}", exc_info=True)

        self._logger.info("Telethon event handlers registered.")

                self._logger.error(f"Error processing deleted event in chat {chat_id_repr}: {e}", exc_info=True)

        self._logger.info("Telethon event handlers registered.")

